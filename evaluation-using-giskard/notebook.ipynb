{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to evaluate a RAG application\n",
    "\n",
    "This example uses [Langchain](https://www.langchain.com) and [Giskard](https://github.com/Giskard-AI/giskard) to evaluate the quality of a RAG application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Website and Split the Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"About Me | Abdul's Portfolio DemoAbdul's Portfolio DemoSearchCtrl‚ÄÜ+‚ÄÜK\\uf8ffüë®‚Äç\\uf8ffüíªAbout MeProjects\\uf8ffüíºJobInsights: Streamlining Your Job Hunt with AI\\uf8ffüåêWebChatAI\\uf8ffü´ÄChest-Cancer-Classification-Using-mlflow-and-DVC\\uf8ffüìâCSVAnalystAI- Your AI Data analyst\\uf8ffüìÑResume Screening Assistance\\uf8ffüìúScriptMaster AI„ÄΩÔ∏èMini Projects Repository \\uf8ffüöÄAbout us\\uf8ffüë®‚Äç\\uf8ffüíªMore About MeVisionSkillsCertificationsthank\\uf8ffü§ùThank You for Visiting My Portfolio!Powered by GitBook\\uf8ffüë®‚Äç\\uf8ffüíªAbout MeWHO AM I !Professional SummaryAbdul Samad is Self-taught Machine Learning Engineer with a strong passion for developing software using a diverse range of ML and non-ML tools and APIs. Proficient in Python, Machine Learning, Deep Learning, NLP, computer vision, and generative AI, demonstrated through extensive project experience. Experienced with LLM libraries such as Langchain and Llama-index, as well as proficient in working with vector databases. Skilled in efficiently managing projects through MLOps and LLMOps.\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='MLOps and LLMOps. Committed to utilizing AI for practical solutions and enhancing user experiences.Currently working as a Machine Learning intern at BrotoType.Keen interest in artificial intelligence, human-computer interaction, and related fields.Exploring MLOps, LLMs, Gen AI, and advanced NLP & DL.Contact:   Socials linkedin discord leetcode instagramyoutubeCopy', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='My skills‚Ä¢ Programming LanguagesPython, C , Java ,php‚Ä¢ Machine LearningSupervised & Unsupervised Learning,Exploratory Data Analysis,Data PreprocessingFeature Engineering‚Ä¢Natural Language Processing‚Ä¢Deep LearningCNN, RNN, Generative AI, GAN, Transformers, Transfer Learning, Large Language Models,Stable Diffusion Model‚Ä¢DatabasesPostgreSQL, Vector Database‚Ä¢Version ControlGit , GitHub , DVC‚Ä¢DeploymentAWS, Huggingface, Streamlit‚Ä¢Data Structures & Algorithms‚Ä¢Statistics and Probability‚Ä¢Frameworks & LibrariesNumPy, Pandas, scikit-learn, Matplotlib, Seaborn,Plotly ,spaCy,NLTK ,PyTorch, TensorFlow, Keras, OpenCV,MLOps tools,MLflow,Docker,hydraLangchain, Huggingface Transformers,OllamaFastAPI, Flask‚Ä¢PlatformsKaggle, Google Colab‚Ä¢Familiar withDocker, DVC,CI/CD Pipelines ,C++, Javaprojects 1 ---------------------------------------------------Go and try JobInsights Application -  https://job-insights.streamlit.app/GitHub - samad-ms/JobInsightsGitHubJobInsights: Streamlining', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"Streamlining Your Job Hunt with AIIn today's competitive job market, finding the right opportunity can be challenging. Job seekers often spend hours scouring through job listings, optimizing their resumes, and crafting personalized cover letters. However, what if there was a way to simplify this process and gain a competitive edge?JobInsights is an innovative AI-powered application designed to revolutionize the job hunting experience. By leveraging cutting-edge technologies, JobInsights aggregates real-time data from popular job platforms such as Indeed, LinkedIn, Glassdoor, and ZipRecruiter, providing job seekers with personalized and comprehensive job summaries, insights, resume optimization tips, email generation tools, and much more.How It WorksUtilizing advanced technologies including GPT-3.5-turbo, Gemini, LIDA (Microsoft), LangChain, and vector databases, JobInsights analyzes and comprehends hundreds of job descriptions. This understanding enables the platform to offer various\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='to offer various features and strategies to secure job interviews and succeed in them, saving significant time by eliminating the need for manual work.FeaturesData Extraction: Extract real-time job information from popular websites.Understand the Job Market: Gain insights into the real-time job market through trend analysis and visualizations.AI Conversation: A general assistant that summarizes job requirements and answers general queries.RAG AI System: A specialized assistant that responds by considering the real-time job market as context.ATS Score Checker and Resume Optimization: Generates concise job descriptions and conducts similarity searches with resumes to identify the top matching resume between job seekers and available positions. It provides keywords to optimize the resume and improve the match.Email Generator: Create customized emails by extracting relevant details of candidates from resumes or portfolio links, enabling users to quickly and efficiently reach out to', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='reach out to potential employers.Future DevelopmentsJobInsights is continuously evolving to offer more exciting features, including:Building resumes from raw text or portfolios that match real-time job requirements.AI-driven interview preparation using resumes and real-time job requirements for specific job roles.AI for preparing learning materials and interview preparation.TechnologiesJobInsights is built using Python and incorporates specialized scraping libraries for data extraction. The user interface is developed using Streamlit for an interactive experience. The application leverages the power of GPT-3.5-turbo for natural language processing, Gemini 1.0 Pro for deep market analysis, LIDA by Microsoft for Visualization tasks, LangChain for efficient data processing, and Pinecone,FAISS as the vector database for storing and retrieving data efficiently.How to ContributeContributions to JobInsights are welcome! If you have any suggestions or improvements, please feel free to open a', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"feel free to open a pull request or an issue on the GitHub repository.LicenseThis project is licensed under the MIT License.ConclusionWith JobInsights, the job hunting process is no longer a daunting task. By leveraging the power of AI and real-time data analysis, job seekers can streamline their job search, optimize their resumes, and secure their dream job. Try JobInsights today and take the first step towards a successful career!projects 2 ---------------------------------------------------Go and try WebChatAI -  https://webchatai.streamlit.app/Let's get started!WebChatAI: Enhancing Conversational AI with Web ScrapingIn the realm of conversational AI, Large Language Models (LLMs) have made significant strides in understanding and generating human-like text. However, their effectiveness is limited by the information they've been trained on. This is where WebChatAI steps in, bridging the gap between existing knowledge and real-time information by utilizing web scraping.The\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='web scraping.The ChallengeLLMs, while powerful, have a finite understanding of the world. They lack real-time information, which can be crucial in dynamic conversations. For instance, an LLM might not have the latest news, product updates, or local events, limiting its ability to provide relevant and up-to-date responses.The SolutionWebChatAI addresses this challenge by scraping the web for information in real-time. When faced with a query that falls outside its pre-existing knowledge base, WebChatAI dynamically searches the web for relevant information, ensuring that its responses are accurate and up-to-date.How WebChatAI WorksQuery Understanding: When a user inputs a query, WebChatAI analyzes the query to determine its intent and context.Knowledge Check: WebChatAI checks its existing knowledge base to see if it has relevant information. If not, it proceeds to the next step.Web Scraping: Using web scraping techniques, WebChatAI searches the web for information related to the', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"related to the query.Response Generation: Based on the information gathered, WebChatAI generates a response that is relevant and up-to-date.Key FeaturesReal-time Information: By scraping the web, WebChatAI ensures that its responses are based on the latest information available.Enhanced Accuracy: With access to real-time data, WebChatAI's responses are more accurate and relevant.Dynamic Learning: WebChatAI can use the information gathered from web scraping to improve its knowledge base over time, ensuring that it stays relevant and up-to-date.Use CasesCustomer Support: WebChatAI can provide real-time assistance to customers, answering queries about products, services, or policies.Information Retrieval: WebChatAI can help users find information on a wide range of topics, from news and events to product reviews and recommendations.Personal Assistance: WebChatAI can act as a virtual assistant, helping users with tasks such as scheduling appointments, making reservations, or finding local\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"or finding local businesses.ConclusionWebChatAI's ability to scrape the web for real-time information sets it apart from traditional LLMs. By combining the power of AI with web scraping, WebChatAI offers a more dynamic and accurate conversational experience, making it a valuable tool for businesses and individuals alike.projects 3 ---------------------------------------------------Tutorial will come soon...Chest-Cancer-Classification-Using-mlflow-and-DVCIntroductionThe project focuses on developing a deep learning model for predicting breast cancer risk and subtype, specifically adenocarcinoma, using chest CT scan images. This model aims to improve early detection and diagnosis, leading to more personalized treatment strategies.WorkflowThe workflow involves several key steps:Data Collection: Obtain chest CT scan images of women diagnosed with adenocarcinoma breast cancer and those without the disease.Data Preprocessing: Clean and prepare the data for training, ensuring it is in a\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"ensuring it is in a suitable format for the deep learning model.Model Training: Train the deep learning model on the preprocessed data to predict breast cancer risk and subtype.Model Evaluation: Evaluate the trained model's performance using metrics such as accuracy and loss.Model Deployment: Deploy the trained model to make predictions on new chest CT scan images.Training PipelineThe training pipeline includes updating various configuration files, such as schema.yaml and params.yaml, to ensure the project's components are correctly configured for training. This ensures that the model is trained using the correct data and parameters.UsageTo use the project, follow these steps:Clone the repository:Copygit clone https://github.com/samad-ms/Chest-Cancer-Classification-Using-mlflow-and-DVC.git\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='cd Chest-Cancer-Classification-Using-mlflow-and-DVCSet up a conda environment:Copyconda create -n ML_project python=3.10 -y', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"conda activate ML_projectRun the application:Copypython app.pyConclusionIn conclusion, the Chest-Cancer-Classification-Using-mlflow-and-DVC project aims to leverage deep learning and DevOps practices to improve breast cancer prediction and subtype classification, ultimately leading to better patient outcomes.Project 4 ---------------------------------------------------------Let's get started!CSVAnalystAI: Streamlining Data Interaction with AIIn today's data-driven world, extracting meaningful insights from raw data is crucial for informed decision-making. Traditional methods of data analysis often require extensive knowledge of programming and data visualization tools, posing a challenge for many users. CSVAnalystAI aims to bridge this gap by providing a user-friendly interface that allows users to interact with their CSV data through natural language queries and generate visualizations effortlessly.OverviewCSVAnalystAI is a Streamlit application designed to revolutionize how users\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='how users interact with their CSV data. By leveraging advanced AI technologies, the application enables users to ask questions in natural language, generate insightful visualizations, and automatically summarize their data. This blog delves into the features, techniques, and technologies that power CSVAnalystAI, making data analysis accessible to everyone.Features1. Chat with CSVOne of the standout features of CSVAnalystAI is the ability to interact with your CSV data through natural language queries. Users can upload their CSV files and ask questions in plain English, such as \"What is the average sales figure for Q1?\" or \"Show me the highest revenue-generating product.\" This feature is powered by natural language processing (NLP) techniques and large language models (LLMs) that understand and interpret user queries.Technologies Used:Natural Language Processing (NLP): To parse and understand user queries.Large Language Models (LLMs): Such as GPT-3.5 to generate responses based on the', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='based on the CSV data.Streamlit: For creating an interactive and user-friendly interface.2. Chat and Visualize with CSVIn addition to answering queries, CSVAnalystAI can generate visualizations based on user queries. Whether you need a bar chart, line graph, or pie chart, the application can create it on the fly. For instance, you can ask, \"Show me a bar chart of monthly sales,\" and CSVAnalystAI will generate the corresponding visualization.Technologies Used:LangChain Agents: To manage data interaction and conversion with DataFrames.Microsoft\\'s Open Source Library - Lida: For creating dynamic and interactive visualizations.Streamlit: For rendering visualizations within the web application.3. Auto SummarizerThe Auto Summarizer feature is designed to provide a quick overview of your CSV data. By leveraging AI, CSVAnalystAI can automatically summarize key metrics and trends within the data, offering insights at a glance. This feature is particularly useful for users who need to', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"users who need to understand large datasets without diving into the details.Technologies Used:AI and Machine Learning Algorithms: For summarizing data and identifying key trends.Natural Language Generation (NLG): To create human-readable summaries.Microsoft's Open Source Library - Lida: For creating dynamic and interactive visualizations.Streamlit: To display summaries and insights in an intuitive format.4. Additional FeaturesCSVAnalystAI is continually evolving, with plans to introduce more exciting features in the future. These may include advanced data manipulation tools, predictive analytics, and integration with other data sources. The goal is to provide a comprehensive toolset for data analysis, making it easier for users to derive insights and make data-driven decisions.Techniques and TechnologiesStreamlitStreamlit is the backbone of CSVAnalystAI, providing a powerful framework for building interactive web applications. With its simplicity and flexibility, Streamlit allows\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"Streamlit allows developers to create responsive user interfaces quickly. The integration with other libraries and technologies makes it an ideal choice for developing data-centric applications like CSVAnalystAI.GPT-3.5Large language models like GPT-3.5 are used to understand and interpret user queries. These models are trained on vast amounts of text data, allowing them to understand natural language and provide coherent and contextually relevant answers. GPT-3.5 plays a crucial role in both the query response and visualization generation features of CSVAnalystAI.LangChain AgentsLangChain agents are employed to handle data interactions and conversions with DataFrames. These agents facilitate smooth and efficient data processing, ensuring that user queries are accurately mapped to the relevant data operations.Microsoft's Lida LibraryMicrosoft's open-source library, Lida, is used to create dynamic and interactive visualizations. Lida offers a wide range of chart types and customization\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"and customization options, enabling CSVAnalystAI to generate visualizations that meet the specific needs of users. The integration of Lida with Streamlit ensures that visualizations are seamlessly rendered within the web application.ConclusionCSVAnalystAI is a groundbreaking application that simplifies data interaction and analysis. By leveraging advanced AI techniques, natural language processing, and powerful visualization libraries, it provides users with an intuitive and efficient way to explore their CSV data. Whether you're a data novice or an experienced analyst, CSVAnalystAI offers a suite of features designed to make data analysis accessible and insightful.Stay tuned for more updates as we continue to enhance CSVAnalystAI with new features and capabilities, empowering users to unlock the full potential of their data.MINI PROJECTS -------------------------------------------------Projects Overview \\uf8ffüìù1. Bangalore Real Estate Price Prediction WebsiteDescription: Develop a real\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='Develop a real estate price prediction website using sklearn and linear regression with the Bangalore home prices dataset from Kaggle. Includes EDA, data cleaning, outlier detection, feature engineering, dimensionality reduction, hyperparameter tuning, k-fold cross-validation, Python Flask server, and a website with HTML/CSS/JavaScript. Predicts real estate prices based on user-input home details. Tech: Python, Numpy, Pandas, Matplotlib, Sklearn, Flask. Repo: https://github.com/samad-ms/bengaluru-house-price-prediction4. EmailSparkAIDescription: Streamlit application for generating various types of emails with different styles (formal, appreciating, not satisfied, neutral) using the OpenAI GPT-3.5 Turbo model.', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='Features: Offers templates for various job-related emails, enabling users to customize the email topic, sender name, recipient name, writing style, and signature. Its interactive interface simplifies email generation, and it uses the OpenAI GPT-3.5 Turbo model to generate responses based on user inputs.', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='Technologies: Python, OpenAI, LangChain, Streamlit.repo: https://github.com/samad-ms/EmailSparkAI5. Sentiment Analysis on IMDBDescription: This project involves training a logistic regression model to perform sentiment analysis on the IMDB dataset. It demonstrates various data science and machine learning techniques, including data preparation, feature extraction using TF-IDF, model training, evaluation, and tracking experiments with MLflow.Features: Splits data into training and test sets while stratifying by sentiment, uses TF-IDF Vectorizer to transform text data into numerical features, trains a logistic regression model with specified hyperparameters, evaluates the model using F1 score and visualizes performance with a confusion matrix, and logs parameters, metrics, and artifacts using MLflow for reproducibility and experiment tracking.technologies: Python, NumPy, Pandas, Matplotlib, Scikit-learn, MLflow, Logistic Regression, TF-IDF.repo:', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='TF-IDF.repo: https://github.com/samad-ms/sentiment_analysis_with_dvc6.Fine-Tuning Llama 2 with QLoRADescription: This project focuses on fine-tuning the Llama 2 model using Quantized Low Rank Adaptation (QLoRA) in a Google Colab environment. The goal is to efficiently adapt large language models to specific tasks with minimal resource usage. Technologies: Python, QLoRA, Google Colab, Transformers, PyTorch, Hugging Face Datasets, BitsAndBytes. repo:https://github.com/samad-ms/Fine_Tune_Llama_27.MNIST Classification Project with HydraDescription: This project is a simple example of image classification using the MNIST dataset. The goal is to classify handwritten digits (0-9) using a ResNet model. Technologies: Python 3.x, PyTorch, torchvision, Hydra. (Hydra is a framework for elegantly configuring complex applications, including managing configuration files, command-line options, and environment variables, making it easier to build and maintain scalable and configurable software', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='software systems.) repo:https://github.com/samad-ms/Mnist_classification_with_hydra8.Fire Weather Index (FWI) PredictionDescription: Predicting the Fire Weather Index (FWI) using Ridge Regression. This model utilizes features like Temperature, RH, Ws, Rain, FFMC, DMC, DC, ISI, BUI, FWI, Classes, and Region. Ridge Regression is chosen for its ability to handle multicollinearity.Technologies: Python, Ridge Regression. repo: https://github.com/samad-ms/fwipredictor9. Chest Cancer Classification ProjectDescription: Developed a Chest Cancer Classification project focusing on adenocarcinoma cancer, achieving 92% accuracy using the VGG16 model. Implemented within an MLOps framework (mlflow) with an end-to-end pipeline. Also, developed a user-friendly interface for the application.Technologies: Python, Deep Learning, MLOps, Docker, DVC, CI/CD, AWS, Flask, DagsHub. repo: https://github.com/samad-ms/Chest-Cancer-Classification-Using-mlflow-and-DVC10.Diabetes Prediction ML Classification', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"ML Classification ProjectDescription: This project aims to predict diabetes based on health data, including features like pregnancies, glucose, blood pressure, and more. It involves data preprocessing, exploratory data analysis, model selection (Logistic Regression), and model deployment. repo : https://github.com/samad-ms/Diabetes-Prediction11. CsvAnalytistAIDescription: Streamlit application designed to help users interact with their CSV data through natural language queries and generate visualizations.Functionality: Allows users to upload CSV files, ask questions in natural language, and generate graphs based on their queries. It also features an auto-summarizer for CSV data.Technologies: Python, Streamlit, OpenAI, LangChain.GitHub Repository: CsvAnalytistAI GitHub RepoReport: CsvAnalytistAI Project ReportFeel free to contribute, suggest improvements, or report issues! Let's collaborate to make these projects even better.Happy coding! \\uf8ffüöÄ\\uf8ffüî•My VisionMy vision is to become a\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='is to become a renowned expert in artificial intelligence and machine learning, pioneering groundbreaking solutions that redefine the capabilities of AI. I aim to drive significant advancements in the field, inspiring others to push the boundaries of what is possible in technology and beyond. Additionally, I want to contribute to open-source projects and give back to the community by providing tutorials and guidance on effective contributions, empowering others to make a positive impact through collaboration and shared knowledge. Moreover, I strive to address the drawbacks of AI and ensure that AI technologies are developed and deployed in an environmentally friendly and sustainable manner, promoting the well-being of the planet. My mission is to actively engage in the AI and machine learning community, collaborating with experts to innovate and develop solutions that address real-world challenges. I am dedicated to advancing the field by continuously learning and applying new', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='and applying new technologies, methodologies, and best practices. My focus is on leveraging AI and machine learning to create practical solutions that have a positive impact on society, prioritizing projects that address pressing issues such as healthcare, sustainability, and education, aiming to develop innovative and sustainable solutions. Additionally, I am dedicated to promoting diversity and inclusion in the AI field, ensuring that the benefits of AI are accessible to all and that its development is guided by a strong moral compass.My skills‚Ä¢ Programming LanguagesPython, C , Java ,php‚Ä¢ Machine LearningSupervised & Unsupervised Learning,Exploratory Data Analysis,Data PreprocessingFeature Engineering‚Ä¢Natural Language Processing‚Ä¢Deep LearningCNN, RNN, Generative AI, GAN, Transformers, Transfer Learning, Large Language Models,Stable Diffusion Model‚Ä¢DatabasesPostgreSQL, Vector Database‚Ä¢Version ControlGit , GitHub , DVC‚Ä¢DeploymentAWS, Huggingface, Streamlit‚Ä¢Data', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content=\"Streamlit‚Ä¢Data Structures & Algorithms‚Ä¢Statistics and Probability‚Ä¢Frameworks & LibrariesNumPy, Pandas, scikit-learn, Matplotlib, Seaborn,Plotly ,spaCy,NLTK ,PyTorch, TensorFlow, Keras, OpenCV,MLOps tools,MLflow,Docker,hydraLangchain, Huggingface Transformers,OllamaFastAPI, Flask‚Ä¢PlatformsKaggle, Google Colab‚Ä¢Familiar withDocker, DVC,CI/CD Pipelines ,C++, Java________________________________________________________________________________________1) A Deep Understanding of Deep Learning by Dr. Mike X Cohen - link - websiteI recently completed Mike X Cohen's deep learning course on Udemy, and I must say, it was an incredibly enriching experience. The course offers a comprehensive dive into the world of deep learning, covering everything from theory to practical implementation using PyTorch.What I appreciated most about the course were the clear and concise explanations of complex topics. Mike has a talent for breaking down difficult concepts into easy-to-understand chunks,\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='chunks, which made grasping the material much easier. The hands-on projects were the highlight for me. They not only reinforced the theoretical concepts but also provided valuable practical experience.One of the things I found particularly valuable was the way the course is structured. It starts with the basics and gradually builds up to more advanced topics. This approach really helped me grasp the fundamentals before moving on to more complex ideas.Overall, I would rate Mike X Cohen\\'s deep learning course a solid 5/5. Whether you\\'re just starting out in deep learning or looking to enhance your skills, I highly recommend this course. It\\'s a fantastic learning resource that provides a solid foundation in deep learning concepts and practical skills.________________________________________________________________________________________2) MLOps Journey: AWS AI/ML Mastery - MLOps 2024 by  Manifold AI - link - websitePractical MLOps for Data Scientists & DevOps Engineers with AWS\" seemed', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='with AWS\" seemed like a promising course, but unfortunately, it didn\\'t meet my expectations. Despite the comprehensive coverage of MLOps concepts and practical implementation using AWS, I found that the course fell short in certain areas.While the course did offer a structured learning path and hands-on projects, I felt that some of the explanations were not as clear as I had hoped. Additionally, there were times when the course content seemed a bit outdated, which was disappointing.On the positive side, the course did provide a good overview of MLOps principles and AWS services, which could be valuable for someone looking to get started in this field. However, for those seeking a more in-depth and up-to-date understanding of MLOps, I would recommend exploring other resources.Overall, I would rate this course a 3/5. It\\'s a decent starting point for beginners, but for those with more experience or higher expectations, it may fall', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='it may fall short.________________________________________________________________________________________3)  Python for Beginners - linkI recently completed the \"Python Programming, OOP in Python, Database connectivity, Web Development using Python\" course on Udemy, and I found it to be an excellent resource for beginners looking to learn Python and its various applications. I would rate it 4.5 out of 5 for its comprehensive coverage of Python fundamentals and practical examples.The course covers a wide range of topics, starting with the basics of Python programming and progressing to more advanced concepts like object-oriented programming (OOP), database connectivity, and web development. The instructor, Navin Reddy, is a corporate trainer and TEDx speaker, who provides clear explanations and demonstrates each concept with live coding examples.One of the things I liked most about the course is its focus on hands-on learning. Throughout the course, you\\'ll work on building real-world', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='building real-world applications, which helps reinforce your understanding of the concepts and prepares you for practical use. The course also includes quizzes and assignments to test your knowledge and reinforce your learning.The section on web development using Django, a high-level web framework for Python, was particularly valuable. Django is used by companies like Google, YouTube, and NASA, making it a valuable skill for aspiring web developers. The course covers the basics of Django and provides a solid foundation for building web applications.Overall, I highly recommend the \"Python Programming, OOP in Python, Database connectivity, Web Development using Python\" course to anyone looking to learn Python from scratch. Whether you\\'re a beginner or an experienced programmer looking to expand your skills, this course provides a comprehensive overview of Python and its applications.________________________________________________________________________________________4) Computer', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow by AI Sciences - link - websiteI recently completed the \"Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.\" course on Udemy, and it was by far my favorite course on the platform. I would rate it 5/5 for its depth of knowledge and comprehensive coverage of computer vision concepts.The course, rated 4.5 out of 5, is designed for all skill levels, from beginners to advanced practitioners. It covers a wide range of topics, starting with the basics of computer vision and progressing to more advanced concepts like deep learning for image analysis and object detection.One of the things I loved about the course was its practical approach. The instructors use live coding examples in Python to explain complex concepts, making it easy to understand and apply the knowledge. The course also includes hands-on projects, such as', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='projects, such as change detection in CCTV cameras and smart DVRs, which help reinforce learning and build practical skills.The course covers a wide range of topics, including image transformations, image filtering and morphology, shape detection, key point detection and matching, motion analysis, object detection, and 3D computer vision. Each topic is explained in detail, with clear explanations and examples.Overall, I highly recommend the \"Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.\" course to anyone interested in learning computer vision. Whether you\\'re a beginner or an experienced practitioner, this course will provide you with the knowledge and skills you need to become an expert in computer vision.________________________________________________________________________________________5) From the Basics of LLMs to Production-Grade Microservice Architecture with Kubernetes by Markus Lang - link I recently', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='- link I recently completed the \"From the Basics of LLMs to Production-Grade Microservice Architecture with Kubernetes\" course on Udemy, and it was an incredibly informative and practical learning experience. The course, rated 4.5 out of 5, is designed to provide a comprehensive understanding of LangChain, a framework crucial for developing generative AI applications.The course starts with the basics, such as the basic usage of the OpenAI API, and gradually progresses to more advanced topics, including input and output mechanisms in LangChain, crafting effective prompt templates for OpenAI models, and understanding critical components like Chains, Callbacks, and Memory.One of the highlights of the course was the focus on advanced concepts like Retrieval Augmented Generation (RAG) and the creation of Autonomous Agents. These sections were particularly insightful, offering practical insights into designing intelligent systems using LangChain.The course also covers topics like Hybrid', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='topics like Hybrid Search, Indexing API, and LangSmith, highlighting their importance in enhancing the efficiency and functionality of AI applications. Additionally, the course integrates theory with practical skills, introducing Microservice Architecture in large language model (LLM) applications and the LangChain Expression Language.Overall, I found the \"From the Basics of LLMs to Production-Grade Microservice Architecture with Kubernetes\" course to be highly valuable for anyone looking to deepen their understanding of LangChain and its applications in generative AI. I would highly recommend it to Python developers and AI enthusiasts interested in mastering LangChain and its advanced features.________________________________________________________________________________________6) Applied Generative AI and Natural Language Processing - link', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='I recently completed the \"Understand Generative AI, Prompt Engineering, Huggingface-Models, LLMs, Vector Databases, RAG, OpenAI, Claude, Llama2\" course on Udemy, and it was a highly enriching experience. The course, rated 4.5 out of 5, is designed for both beginners and seasoned professionals in the field of Natural Language Processing (NLP) and Generative AI.The course covers a wide range of topics, starting with an introduction to NLP and its fundamental principles. I particularly enjoyed the sections on word embeddings, transformers, and applying Huggingface for pre-trained networks. The explanations were clear, and the hands-on exercises helped solidify my understanding of these concepts.One of the highlights of the course was the focus on model fine-tuning, which is often necessary to adapt pre-trained networks to specific tasks or datasets. The section on vector databases was also fascinating, providing insights into how these databases can simplify text querying.The course also', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='course also delves into advanced topics such as prompt engineering, retrieval-augmented generation (RAG), and working with OpenAI\\'s ChatGPT API. These sections were incredibly insightful, offering practical strategies and techniques for improving the performance of NLP models.The course culminates in a capstone project where students create a chatbot to interact with a PDF document, demonstrating the real-world application of the skills learned throughout the course.Overall, I found the \"Understand Generative AI, Prompt Engineering, Huggingface-Models, LLMs, Vector Databases, RAG, OpenAI, Claude, Llama2\" course to be highly valuable for anyone looking to deepen their understanding of NLP and Generative AI. I would highly recommend it to anyone interested in this field.________________________________________________________________________________________7) NLP - Natural Language Processing by Lazy ProgrammerI enrolled in the \"NLP: Use Markov Models, NLTK, Artificial Intelligence,', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='Intelligence, Deep Learning, Machine Learning, and Data Science in Python\" course with high hopes, considering its impressive rating of 4.8 out of 5. The course offers a comprehensive 4-in-1 approach, covering vector models, text preprocessing, probability models, Markov models, machine learning, and deep learning methods in NLP.In the first part, which focuses on vector models and text preprocessing, I appreciated the detailed explanations on converting text into vectors using techniques like CountVectorizer, TF-IDF, word2vec, and GloVe. However, I found that some of the explanations could have been clearer, especially for beginners.The second part, covering probability models and Markov models, was insightful. I particularly enjoyed learning about the practical applications of these models in text classification, article spinning, and text generation. These concepts are crucial for understanding advanced models like BERT and GPT-3.The third part, which delves into machine learning', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='machine learning methods, provided a good overview of classic NLP tasks such as spam detection, sentiment analysis, and topic modeling. The application-focused approach was helpful, but I wished there was more emphasis on the underlying algorithms.The fourth part, focusing on deep learning methods, was perhaps the most engaging. I appreciated learning about modern neural network architectures like CNNs, RNNs, LSTM, and GRU, which are essential for understanding advanced AI models.Overall, while the course covers a wide range of topics and provides hands-on learning opportunities, I felt that some sections could be improved for better clarity and depth. I would rate this course a 4/5 for its comprehensive coverage of NLP concepts and practical applications.________________________________________________________________________________________NextJobInsights: Streamlining Your Job Hunt with AILast updated 2 minutes agoOn this pageSocialsMy skillsprojects 1', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='skillsprojects 1 ---------------------------------------------------JobInsights: Streamlining Your Job Hunt with AIprojects 2 ---------------------------------------------------projects 3 ---------------------------------------------------Project 4 ---------------------------------------------------------CSVAnalystAI: Streamlining Data Interaction with AIOverviewFeaturesTechniques and TechnologiesConclusionMINI PROJECTS -------------------------------------------------Projects Overview \\uf8ffüìùMy VisionMy skillsGitHub - samad-ms/WebChatAI: WebChatAI is an RAG application , which is capable of chating with any website out thereGitHubGo and get the codeGitHub - samad-ms/CsvAnalistAIGitHub', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "\n",
    "loader = WebBaseLoader(\"https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1\")\n",
    "documents = loader.load_and_split(text_splitter)\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Content in a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    documents, embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the content in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About Me | Abdul's Portfolio DemoAbdul's Portf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLOps and LLMOps. Committed to utilizing AI fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My skills‚Ä¢ Programming LanguagesPython, C , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Streamlining Your Job Hunt with AIIn today's c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to offer various features and strategies to se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reach out to potential employers.Future Develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feel free to open a pull request or an issue o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>web scraping.The ChallengeLLMs, while powerful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>related to the query.Response Generation: Base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>or finding local businesses.ConclusionWebChatA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  About Me | Abdul's Portfolio DemoAbdul's Portf...\n",
       "1  MLOps and LLMOps. Committed to utilizing AI fo...\n",
       "2  My skills‚Ä¢ Programming LanguagesPython, C , ...\n",
       "3  Streamlining Your Job Hunt with AIIn today's c...\n",
       "4  to offer various features and strategies to se...\n",
       "5  reach out to potential employers.Future Develo...\n",
       "6  feel free to open a pull request or an issue o...\n",
       "7  web scraping.The ChallengeLLMs, while powerful...\n",
       "8  related to the query.Response Generation: Base...\n",
       "9  or finding local businesses.ConclusionWebChatA..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([d.page_content for d in documents], columns=[\"text\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a Knowledge Base using the DataFrame we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<giskard.rag.knowledge_base.KnowledgeBase at 0x25543cddd50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from giskard.rag import KnowledgeBase\n",
    "\n",
    "knowledge_base = KnowledgeBase(df)\n",
    "knowledge_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:giskard.rag:Finding topics in the knowledge base.\n",
      "c:\\Users\\abdulsamad\\anaconda3\\envs\\evaluation\\Lib\\site-packages\\umap\\umap_.py:2437: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n",
      "INFO:giskard.rag:Found 3 topics in the knowledge base.\n",
      "Generating questions: 100%|██████████| 10/10 [01:12<00:00,  7.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from giskard.rag import generate_testset\n",
    "\n",
    "testset = generate_testset(\n",
    "    knowledge_base,\n",
    "    num_questions=10,\n",
    "    agent_description=\"A chatbot answering questions about Abdul Samad from his portfolio Website\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display a few samples from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the aim of the Chest-Cancer-Classification-Using-mlflow-and-DVC project?\n",
      "Reference answer: The project focuses on developing a deep learning model for predicting breast cancer risk and subtype, specifically adenocarcinoma, using chest CT scan images. This model aims to improve early detection and diagnosis, leading to more personalized treatment strategies.\n",
      "Reference context:\n",
      "Document 9: or finding local businesses.ConclusionWebChatAI's ability to scrape the web for real-time information sets it apart from traditional LLMs. By combining the power of AI with web scraping, WebChatAI offers a more dynamic and accurate conversational experience, making it a valuable tool for businesses and individuals alike.projects 3 ---------------------------------------------------Tutorial will come soon...Chest-Cancer-Classification-Using-mlflow-and-DVCIntroductionThe project focuses on developing a deep learning model for predicting breast cancer risk and subtype, specifically adenocarcinoma, using chest CT scan images. This model aims to improve early detection and diagnosis, leading to more personalized treatment strategies.WorkflowThe workflow involves several key steps:Data Collection: Obtain chest CT scan images of women diagnosed with adenocarcinoma breast cancer and those without the disease.Data Preprocessing: Clean and prepare the data for training, ensuring it is in a\n",
      "\n",
      "Document 7: web scraping.The ChallengeLLMs, while powerful, have a finite understanding of the world. They lack real-time information, which can be crucial in dynamic conversations. For instance, an LLM might not have the latest news, product updates, or local events, limiting its ability to provide relevant and up-to-date responses.The SolutionWebChatAI addresses this challenge by scraping the web for information in real-time. When faced with a query that falls outside its pre-existing knowledge base, WebChatAI dynamically searches the web for relevant information, ensuring that its responses are accurate and up-to-date.How WebChatAI WorksQuery Understanding: When a user inputs a query, WebChatAI analyzes the query to determine its intent and context.Knowledge Check: WebChatAI checks its existing knowledge base to see if it has relevant information. If not, it proceeds to the next step.Web Scraping: Using web scraping techniques, WebChatAI searches the web for information related to the\n",
      "******************\n",
      "\n",
      "Question 2: What topics does the 'Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.' course cover?\n",
      "Reference answer: The course covers a wide range of topics, including image transformations, image filtering and morphology, shape detection, key point detection and matching, motion analysis, object detection, and 3D computer vision.\n",
      "Reference context:\n",
      "Document 31: Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow by AI Sciences - link - websiteI recently completed the \"Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.\" course on Udemy, and it was by far my favorite course on the platform. I would rate it 5/5 for its depth of knowledge and comprehensive coverage of computer vision concepts.The course, rated 4.5 out of 5, is designed for all skill levels, from beginners to advanced practitioners. It covers a wide range of topics, starting with the basics of computer vision and progressing to more advanced concepts like deep learning for image analysis and object detection.One of the things I loved about the course was its practical approach. The instructors use live coding examples in Python to explain complex concepts, making it easy to understand and apply the knowledge. The course also includes hands-on projects, such as\n",
      "\n",
      "Document 32: projects, such as change detection in CCTV cameras and smart DVRs, which help reinforce learning and build practical skills.The course covers a wide range of topics, including image transformations, image filtering and morphology, shape detection, key point detection and matching, motion analysis, object detection, and 3D computer vision. Each topic is explained in detail, with clear explanations and examples.Overall, I highly recommend the \"Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.\" course to anyone interested in learning computer vision. Whether you're a beginner or an experienced practitioner, this course will provide you with the knowledge and skills you need to become an expert in computer vision.________________________________________________________________________________________5) From the Basics of LLMs to Production-Grade Microservice Architecture with Kubernetes by Markus Lang - link I recently\n",
      "******************\n",
      "\n",
      "Question 3: What are the main competencies Abdul Samad possesses in the domain of artificial intelligence and machine learning, and how does he apply these skills in his work?\n",
      "Reference answer: Abdul Samad's key skills in machine learning and AI include Programming Languages like Python, C , Java ,php, Supervised & Unsupervised Learning, Exploratory Data Analysis, Data Preprocessing, Feature Engineering, Natural Language Processing, Deep Learning techniques such as CNN, RNN, Generative AI, GAN, Transformers, Transfer Learning, Large Language Models, Stable Diffusion Model, Databases like PostgreSQL, Vector Database, Version Control tools like Git , GitHub , DVC, and Deployment tools like AWS, Huggingface, Streamlit.\n",
      "Reference context:\n",
      "Document 24: is to become a renowned expert in artificial intelligence and machine learning, pioneering groundbreaking solutions that redefine the capabilities of AI. I aim to drive significant advancements in the field, inspiring others to push the boundaries of what is possible in technology and beyond. Additionally, I want to contribute to open-source projects and give back to the community by providing tutorials and guidance on effective contributions, empowering others to make a positive impact through collaboration and shared knowledge. Moreover, I strive to address the drawbacks of AI and ensure that AI technologies are developed and deployed in an environmentally friendly and sustainable manner, promoting the well-being of the planet. My mission is to actively engage in the AI and machine learning community, collaborating with experts to innovate and develop solutions that address real-world challenges. I am dedicated to advancing the field by continuously learning and applying new\n",
      "\n",
      "Document 25: and applying new technologies, methodologies, and best practices. My focus is on leveraging AI and machine learning to create practical solutions that have a positive impact on society, prioritizing projects that address pressing issues such as healthcare, sustainability, and education, aiming to develop innovative and sustainable solutions. Additionally, I am dedicated to promoting diversity and inclusion in the AI field, ensuring that the benefits of AI are accessible to all and that its development is guided by a strong moral compass.My skills‚Ä¢ Programming LanguagesPython, C , Java ,php‚Ä¢ Machine LearningSupervised & Unsupervised Learning,Exploratory Data Analysis,Data PreprocessingFeature Engineering‚Ä¢Natural Language Processing‚Ä¢Deep LearningCNN, RNN, Generative AI, GAN, Transformers, Transfer Learning, Large Language Models,Stable Diffusion Model‚Ä¢DatabasesPostgreSQL, Vector Database‚Ä¢Version ControlGit , GitHub , DVC‚Ä¢DeploymentAWS, Huggingface, Streamlit‚Ä¢Data\n",
      "******************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_df = testset.to_pandas()\n",
    "\n",
    "for index, row in enumerate(test_set_df.head(3).iterrows()):\n",
    "    print(f\"Question {index + 1}: {row[1]['question']}\")\n",
    "    print(f\"Reference answer: {row[1]['reference_answer']}\")\n",
    "    print(\"Reference context:\")\n",
    "    print(row[1]['reference_context'])\n",
    "    print(\"******************\", end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now save the test set to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.save(\"test-set.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't \n",
      "answer the question, reply \"I don't know\".\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the RAG Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a retriever from the Vector Store that will allow us to get the top similar documents to a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"About Me | Abdul's Portfolio DemoAbdul's Portfolio DemoSearchCtrl‚ÄÜ+‚ÄÜK\\uf8ffüë®‚Äç\\uf8ffüíªAbout MeProjects\\uf8ffüíºJobInsights: Streamlining Your Job Hunt with AI\\uf8ffüåêWebChatAI\\uf8ffü´ÄChest-Cancer-Classification-Using-mlflow-and-DVC\\uf8ffüìâCSVAnalystAI- Your AI Data analyst\\uf8ffüìÑResume Screening Assistance\\uf8ffüìúScriptMaster AI„ÄΩÔ∏èMini Projects Repository \\uf8ffüöÄAbout us\\uf8ffüë®‚Äç\\uf8ffüíªMore About MeVisionSkillsCertificationsthank\\uf8ffü§ùThank You for Visiting My Portfolio!Powered by GitBook\\uf8ffüë®‚Äç\\uf8ffüíªAbout MeWHO AM I !Professional SummaryAbdul Samad is Self-taught Machine Learning Engineer with a strong passion for developing software using a diverse range of ML and non-ML tools and APIs. Proficient in Python, Machine Learning, Deep Learning, NLP, computer vision, and generative AI, demonstrated through extensive project experience. Experienced with LLM libraries such as Langchain and Llama-index, as well as proficient in working with vector databases. Skilled in efficiently managing projects through MLOps and LLMOps.\", metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='My skills‚Ä¢ Programming LanguagesPython, C , Java ,php‚Ä¢ Machine LearningSupervised & Unsupervised Learning,Exploratory Data Analysis,Data PreprocessingFeature Engineering‚Ä¢Natural Language Processing‚Ä¢Deep LearningCNN, RNN, Generative AI, GAN, Transformers, Transfer Learning, Large Language Models,Stable Diffusion Model‚Ä¢DatabasesPostgreSQL, Vector Database‚Ä¢Version ControlGit , GitHub , DVC‚Ä¢DeploymentAWS, Huggingface, Streamlit‚Ä¢Data Structures & Algorithms‚Ä¢Statistics and Probability‚Ä¢Frameworks & LibrariesNumPy, Pandas, scikit-learn, Matplotlib, Seaborn,Plotly ,spaCy,NLTK ,PyTorch, TensorFlow, Keras, OpenCV,MLOps tools,MLflow,Docker,hydraLangchain, Huggingface Transformers,OllamaFastAPI, Flask‚Ä¢PlatformsKaggle, Google Colab‚Ä¢Familiar withDocker, DVC,CI/CD Pipelines ,C++, Javaprojects 1 ---------------------------------------------------Go and try JobInsights Application -  https://job-insights.streamlit.app/GitHub - samad-ms/JobInsightsGitHubJobInsights: Streamlining', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='TF-IDF.repo: https://github.com/samad-ms/sentiment_analysis_with_dvc6.Fine-Tuning Llama 2 with QLoRADescription: This project focuses on fine-tuning the Llama 2 model using Quantized Low Rank Adaptation (QLoRA) in a Google Colab environment. The goal is to efficiently adapt large language models to specific tasks with minimal resource usage. Technologies: Python, QLoRA, Google Colab, Transformers, PyTorch, Hugging Face Datasets, BitsAndBytes. repo:https://github.com/samad-ms/Fine_Tune_Llama_27.MNIST Classification Project with HydraDescription: This project is a simple example of image classification using the MNIST dataset. The goal is to classify handwritten digits (0-9) using a ResNet model. Technologies: Python 3.x, PyTorch, torchvision, Hydra. (Hydra is a framework for elegantly configuring complex applications, including managing configuration files, command-line options, and environment variables, making it easier to build and maintain scalable and configurable software', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'}),\n",
       " Document(page_content='skillsprojects 1 ---------------------------------------------------JobInsights: Streamlining Your Job Hunt with AIprojects 2 ---------------------------------------------------projects 3 ---------------------------------------------------Project 4 ---------------------------------------------------------CSVAnalystAI: Streamlining Data Interaction with AIOverviewFeaturesTechniques and TechnologiesConclusionMINI PROJECTS -------------------------------------------------Projects Overview \\uf8ffüìùMy VisionMy skillsGitHub - samad-ms/WebChatAI: WebChatAI is an RAG application , which is capable of chating with any website out thereGitHubGo and get the codeGitHub - samad-ms/CsvAnalistAIGitHub', metadata={'source': 'https://abduls-organization-13.gitbook.io/abduls-portfolio-demo-1#my-skills-1', 'title': \"About Me | Abdul's Portfolio Demo\", 'description': 'WHO AM I !', 'language': 'en'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "retriever.invoke(\"Who is Abdul ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=MODEL)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the chain works by testing it with a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abdul is a self-taught Machine Learning Engineer with a strong passion for developing software using a diverse range of ML and non-ML tools and APIs. He is proficient in Python, Machine Learning, Deep Learning, NLP, computer vision, and generative AI, as demonstrated through extensive project experience.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"who is Abdul ?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a function that invokes the chain with a specific question and returns the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_fn(question, history=None):\n",
    "    return chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `evaluate()` function to evaluate the model on the test set. This function will compare the answers from the chain with the reference answers in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking questions to the agent: 100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n",
      "CorrectnessMetric evaluation: 100%|██████████| 10/10 [00:23<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from giskard.rag import evaluate\n",
    "\n",
    "report = evaluate(answer_fn, testset=testset, knowledge_base=knowledge_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let now display the report.\n",
    "\n",
    "Here are the five components of our RAG application:\n",
    "\n",
    "* **Generator**: This is the LLM used in the chain to generate the answers.\n",
    "* **Retriever**: This is the retriever that fetches relevant documents from the knowledge base according to a query.\n",
    "* **Rewriter**: This is a component that rewrites the user query to make it more relevant to the knowledge base or to account for chat history.\n",
    "* **Router**: This is a component that filters the query of the user based on his intentions.\n",
    "* **Knowledge Base**: This is the set of documents given to the RAG to generate the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"bff3ab0c-f8e2-4ab9-ad95-70e97dc22aa4\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"bff3ab0c-f8e2-4ab9-ad95-70e97dc22aa4\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"bff3ab0c-f8e2-4ab9-ad95-70e97dc22aa4\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "\n",
       "\n",
       "<style>\n",
       "    body{\n",
       "  background: #18181B;\n",
       "}\n",
       "\n",
       ".main{\n",
       "  font-family: \"Noto Sans\", ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif, \"Apple Color Emoji\", \"Segoe UI Emoji\", \"Segoe UI Symbol\", \"Noto Color Emoji\";\n",
       "  color: #FDFDFD;\n",
       "}\n",
       "\n",
       "h1 {\n",
       "  font-size: 2.5rem;\n",
       "  color: white;\n",
       "}\n",
       "\n",
       "h3 {\n",
       "  font-size: 1.5rem;\n",
       "  background: #0c087c;\n",
       "  padding: 10px;\n",
       "  margin: 0px;\n",
       "  border: 1px solid #6b7280;}\n",
       "\n",
       ".extended-title{\n",
       "  width:100%;\n",
       "}\n",
       "\n",
       "#gsk-overview{\n",
       "  display:flex;\n",
       "}\n",
       "\n",
       "h4 {\n",
       "  font-size: 1rem;\n",
       "  background: #27272A;\n",
       "  padding: 10px;\n",
       "  margin: 0px;\n",
       "  border-bottom: 1px solid #6b7280;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "  font-size: 1.5rem;\n",
       "  margin-top: 3px;\n",
       "  color:#000000;\n",
       "}\n",
       "\n",
       ".header{\n",
       "  display: flex;\n",
       "  justify-content: center;\n",
       "  align-items: center;\n",
       "}\n",
       ".header > * {\n",
       "  margin-inline: 20px;\n",
       "}\n",
       "\n",
       ".flex-row {\n",
       "  display: flex;\n",
       "  flex-direction: row;\n",
       "  padding:10px;\n",
       "  border: 1px solid #27272A;\n",
       "}\n",
       "\n",
       ".flex-row>div {\n",
       "  flex: auto;\n",
       "  box-sizing: border-box;\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  justify-content: center;\n",
       "  align-items: center;\n",
       "}\n",
       "\n",
       "progress[value] {\n",
       "  --background: #6D6D6D;\n",
       "  -webkit-appearance: none;\n",
       "  -moz-appearance: none;\n",
       "  appearance: none;\n",
       "  border: none;\n",
       "  height: 4px;\n",
       "  margin: 0 10px;\n",
       "  border-radius: 10em;\n",
       "  background: var(--background);\n",
       "}\n",
       "\n",
       "progress[value]::-webkit-progress-bar {\n",
       "  border-radius: 10em;\n",
       "  background: var(--background);\n",
       "}\n",
       "\n",
       "progress[value]::-webkit-progress-value {\n",
       "  border-radius: 10em;\n",
       "  background: var(--color);\n",
       "}\n",
       "\n",
       "progress[value]::-moz-progress-bar {\n",
       "  border-radius: 10em;\n",
       "  background: var(--color);\n",
       "}\n",
       "\n",
       "label {\n",
       "  font-size: 20px;\n",
       "  font-weight: bold;\n",
       "  display: block;\n",
       "  margin: 20px 0;\n",
       "}\n",
       "\n",
       ".tab {\n",
       "  overflow: hidden;\n",
       "  border: 1px solid #27272A;\n",
       "  background-color: #27272A;\n",
       "}\n",
       "\n",
       ".tab button {\n",
       "  background-color: inherit;\n",
       "  float: left;\n",
       "  border: none;\n",
       "  outline: none;\n",
       "  cursor: pointer;\n",
       "  padding: 14px 16px;\n",
       "  transition: 0.3s;\n",
       "  color: #ffffff;\n",
       "  font-size:1.2rem;\n",
       "}\n",
       "\n",
       ".tab div {\n",
       "  background-color: inherit;\n",
       "  float: left;\n",
       "  border: none;\n",
       "  outline: none;\n",
       "  cursor: pointer;\n",
       "  padding: 14px 16px;\n",
       "  transition: 0.3s;\n",
       "  color: #ffffff;\n",
       "  font-size: 1.2rem;\n",
       "}\n",
       "\n",
       ".tab button:hover {\n",
       "  background-color: #18181B;\n",
       "}\n",
       "\n",
       ".tab-title{\n",
       "  font-size: 1.5rem;\n",
       "  font-weight: bold;\n",
       "  margin-bottom:-5px;\n",
       "}\n",
       "\n",
       ".tab button.active {\n",
       "  background-color: #18181B;\n",
       "  border-top: 1px solid #6b7280;\n",
       "  border-bottom: 1px solid #18181B;\n",
       "  border-left: 1px solid #6b7280;\n",
       "  border-right: 1px solid #6b7280;\n",
       "}\n",
       "\n",
       ".tabcontent {\n",
       "  display: none;\n",
       "  padding: 6px 12px;\n",
       "  background: #18181B;\n",
       "  border: 1px solid #27272A;\n",
       "  border-top: 1px solid #6b7280;\n",
       "  margin-top: -2px;\n",
       "}\n",
       "\n",
       "#gsk-advice {\n",
       "  display: flex;\n",
       "  justify-content: center;\n",
       "}\n",
       "\n",
       "#gsk-metrics{\n",
       "  width:100%;\n",
       "}\n",
       "\n",
       "#recommendation {\n",
       "  margin-top: 20px;\n",
       "  padding: 20px;\n",
       "  border-radius: 10px;\n",
       "  background-color: #e1ce86;\n",
       "  color: #27272A;\n",
       "  width:95%;\n",
       "  box-shadow: 0 4px 8px 0 #000000, 0 6px 20px 0 #000000;\n",
       "  font-size: 12pt;\n",
       "}\n",
       "\n",
       ".separator {\n",
       "  margin: 20px 0;\n",
       "}\n",
       "\n",
       ".separator-border {\n",
       "  margin: 20px 0;\n",
       "  border-bottom: 1px solid #6b7280;\n",
       "}\n",
       "\n",
       "#gsk-rag{\n",
       "  margin: 32px 28px;\n",
       "  padding: 12px 24px;\n",
       "  background-color: #111516;\n",
       "}\n",
       "\n",
       ".section-container {\n",
       "  margin-bottom: 32px;\n",
       "}\n",
       "\n",
       "  .components-container {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    align-items: flex-start;\n",
       "    gap: 0 32px;\n",
       "  }\n",
       "\n",
       "    .component-card {\n",
       "      background-color: #14191B;\n",
       "      border-radius: 16px;\n",
       "      padding: 28px 32px 32px 32px;\n",
       "      display: flex;\n",
       "      flex-flow: column;\n",
       "      align-items: center;\n",
       "      margin-top: 32px;\n",
       "      flex-grow: 1;\n",
       "    }\n",
       "\n",
       "    .component-title {\n",
       "      font-size: 12px;\n",
       "      font-weight: 500;\n",
       "      color: #B1B1B1;\n",
       "      padding-bottom: 8px;\n",
       "    }\n",
       "\n",
       "    .component-value {\n",
       "      font-size: 32px;\n",
       "      font-weight: 500;\n",
       "      padding-bottom: 12px;\n",
       "    }\n",
       "      \n",
       "      .text-green {\n",
       "        color: #04B543;\n",
       "      }\n",
       "      \n",
       "      .text-orange {\n",
       "        color: #E76E0F;\n",
       "      }\n",
       "      \n",
       "      .text-red {\n",
       "        color: #EA3829;\n",
       "      }\n",
       "\n",
       "      .tooltip {\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "      }\n",
       "\n",
       "      .tooltip .tooltiptext {\n",
       "        visibility: hidden;\n",
       "        width: 120px;\n",
       "        background-color: #464646;\n",
       "        color: #E6E6E6;\n",
       "        text-align: center;\n",
       "        border-radius: 6px;\n",
       "        position: absolute;\n",
       "        z-index: 1;\n",
       "        top: 150%;\n",
       "        left: 50%;\n",
       "        margin-left: -60px;\n",
       "        font-size: 12px;\n",
       "        padding: 12px;\n",
       "      }\n",
       "      \n",
       "      .tooltip .tooltiptext::after {\n",
       "        content: \"\";\n",
       "        position: absolute;\n",
       "        bottom: 100%;\n",
       "        left: 50%;\n",
       "        margin-left: -5px;\n",
       "        border-width: 5px;\n",
       "        border-style: solid;\n",
       "        border-color: transparent transparent black transparent;\n",
       "      }\n",
       "      \n",
       "      .tooltip:hover .tooltiptext {\n",
       "        visibility: visible;\n",
       "      }\n",
       "\n",
       "    .overall-card {\n",
       "      background-color: #026836;\n",
       "      border-radius: 16px;\n",
       "      padding: 28px 32px 32px 32px;\n",
       "      display: flex;\n",
       "      flex-flow: column;\n",
       "      align-items: center;\n",
       "      justify-content: center;\n",
       "      margin-top: 32px;\n",
       "      flex-grow: 1;\n",
       "    }\n",
       "  \n",
       "    .overall-title {\n",
       "      font-size: 12px;\n",
       "      font-weight: 500;\n",
       "      color: #E6E6E6;\n",
       "      padding: 14px 0 8px 0;\n",
       "      text-transform: uppercase;\n",
       "     }\n",
       "  \n",
       "    .overall-value {\n",
       "      font-size: 32px;\n",
       "      font-weight: 500;\n",
       "      padding-bottom: 12px;\n",
       "      color: #E6E6E6;\n",
       "    }\n",
       "\n",
       ".section-title {\n",
       "  font-size: 12px;\n",
       "  color: #B1B1B1;\n",
       "  margin-bottom: 20px;\n",
       "  text-align: left;\n",
       "  width: 100%;\n",
       "}\n",
       "\n",
       ".section-content {\n",
       "  color: #E6E6E6;\n",
       "  font-size: 20px;\n",
       "  line-height: 1.5;\n",
       "}\n",
       "\n",
       ".section-card {\n",
       "  background-color: #14191B;\n",
       "  border-radius: 16px;\n",
       "  padding: 28px 32px 32px 32px;\n",
       "  display: flex;\n",
       "  flex-flow: column;\n",
       "  align-items: center;\n",
       "}\n",
       "\n",
       ".correctness-indicator{\n",
       "  padding: 20px;\n",
       "  border-radius: 50px;\n",
       "  font-size: 16pt;\n",
       "  box-shadow: 0 4px 8px 0 #000000, 0 6px 20px 0 #000000;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".metric-title{\n",
       "  margin: -2px;\n",
       "  border-bottom: none;\n",
       "}\n",
       "\n",
       ".hist-row {\n",
       "  display: flex;\n",
       "  flex-direction: row;\n",
       "  padding: 10px;\n",
       "  justify-content: space-around;\n",
       "  width: 85%;\n",
       "}\n",
       "\n",
       ".hist-row>div {\n",
       "  flex: auto;\n",
       "  box-sizing: border-box;\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  justify-content: center;\n",
       "  align-items: center;\n",
       "  padding-left: 1%;\n",
       "  padding-right: 1%;\n",
       "}\n",
       "\n",
       ".tab-row{\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "}\n",
       "\n",
       "#component-table{\n",
       "  width:50%;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "\n",
       ".green{\n",
       "  background-color: #0a980a;\n",
       "}\n",
       "\n",
       ".orange {\n",
       "  background-color: #e5b62a;\n",
       "}\n",
       "\n",
       ".red {\n",
       "  background-color: #ba0e0e;\n",
       "}\n",
       "\n",
       ".progress-green {\n",
       "  --color: #04B543;\n",
       "}\n",
       "\n",
       ".progress-orange {\n",
       "  --color: #E76E0F;\n",
       "}\n",
       "\n",
       ".progress-red {\n",
       "  --color: #EA3829;\n",
       "}\n",
       "\n",
       ".corr-plot{\n",
       "  flex: 1;\n",
       "  padding-left: 2%;\n",
       "}\n",
       "\n",
       ".tooltip-text {\n",
       "  position: absolute;\n",
       "  display: none;\n",
       "  visibility: hidden;\n",
       "  z-index: 1;\n",
       "  top: 100%;\n",
       "  left: 0%;\n",
       "  width: 100%;\n",
       "  color: white;\n",
       "  font-size: 12px;\n",
       "  background-color: #2d3d4c;\n",
       "  border-radius: 10px;\n",
       "  padding: 10px 15px 10px 15px;\n",
       "}\n",
       "\n",
       "#fade {\n",
       "  opacity: 1;\n",
       "  transition: opacity 0.5s;\n",
       "}\n",
       "\n",
       "#delay {\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s;\n",
       "  transition-delay: 1s;\n",
       "}\n",
       "\n",
       "td {\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "tr:hover .tooltip-text {\n",
       "  display: block;\n",
       "  visibility: visible;\n",
       "}\n",
       "\n",
       ".tr:hover #fade {\n",
       "  opacity: 1;\n",
       "}\n",
       "\n",
       ".tr:hover #delay {\n",
       "  opacity: 1;\n",
       "}\n",
       "\n",
       ".callout {\n",
       "  padding: 0.5rem 1rem 0.5rem 3rem;\n",
       "  background: #D9EDF9;\n",
       "  border: 3px solid #0088D1;\n",
       "  color: #272eb5;\n",
       "  position: relative;\n",
       "  max-width: 40rem;\n",
       "  border-radius: 10px;\n",
       "  margin-top: 10%;\n",
       "  font-size: 11pt;\n",
       "}\n",
       "\n",
       ".callout-icon {\n",
       "  content: \"\";\n",
       "\n",
       "  /* SVG via a data URI! */\n",
       "  background-size: cover;\n",
       "  width: 1.5rem;\n",
       "  height: 1.5rem;\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  left: 0.9rem;\n",
       "  top: 1.1rem;\n",
       "}\n",
       "\n",
       ".callout-icon svg{\n",
       "  fill: #016ca7;\n",
       "}\n",
       ".callout p+p {\n",
       "  margin-top: 1em;\n",
       "}\n",
       "\n",
       ".callout a {\n",
       "  color: #272eb5;\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       "#gsk-logo {\n",
       "  padding-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<script src=\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\" integrity=\"sha384-5QIrjQuyo4I/x6DK/Sau33lcA3hT2TCZGr9vbk+2ebd7Da6FnR1amdM+9B5xOrSf\" crossorigin=\"anonymous\"></script>\n",
       "<script src=\"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\" integrity=\"sha384-tXTWPp/bAKa+K9RPuXh7DNvye0Mv+P+6y4rAMVy+pWapsnXg9UG7g20WZ0N4i28A\" crossorigin=\"anonymous\"></script>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"main\">\n",
       "    <div id=\"gsk-rag\" class=\"dark:text-white dark:bg-zinc-800 rounded border border-gray-500\">\n",
       "        <div class=\"header border-b border-b-gray-500\">\n",
       "            \n",
       "                <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"60\" height=\"30\" viewBox=\"0 0 30 15\" fill=\"none\" id=\"gsk-logo\">\n",
       "                    <path fill=\"#fff\" fill-rule=\"evenodd\"\n",
       "                        d=\"M22.504 1.549a4.196 4.196 0 0 1 2.573-.887v.002a3.783 3.783 0 0 1 2.706 1.086 3.783 3.783 0 0 1 1.126 2.69 3.771 3.771 0 0 1-1.126 2.69 3.77 3.77 0 0 1-2.706 1.085l-4.794.011-2.533 3.467L8.203 15l2.881-3.335a9.829 9.829 0 0 1-4.663-1.68H3.185L0 7.163h3.934C4.263 3.165 8.187 0 12.96 0c2.24 0 4.489.696 6.175 1.909a7.423 7.423 0 0 1 1.882 1.919 4.194 4.194 0 0 1 1.487-2.28ZM7.05 3.249l3.91 3.915h1.505L7.89 2.584a7.773 7.773 0 0 0-.84.665Zm4.079-2.008 5.923 5.923h1.503l-6.086-6.087c-.45.023-.898.078-1.34.164ZM4.574 8.226h-1.77l.784.693h1.584a8.454 8.454 0 0 1-.598-.693Zm9.479 0H5.984c1.469 1.477 3.656 2.377 5.977 2.422l2.092-2.422Zm-2.458 4.472 5.492-1.902 1.878-2.569h-3.508l-3.862 4.47Zm10.361-5.552h3.265a2.714 2.714 0 0 0 1.747-4.648 2.711 2.711 0 0 0-1.888-.773 3.127 3.127 0 0 0-3.123 3.124v2.297Zm3.659-3.73a.677.677 0 1 1-.134 1.348.677.677 0 0 1 .134-1.348Z\"\n",
       "                        clip-rule=\"evenodd\" />\n",
       "                </svg>\n",
       "            <h1>RAG Evaluation Toolkit</h1>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"components-container\">\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">GENERATOR</div>\n",
       "                    <div class=\"component-value tooltip  text-orange \">\n",
       "                        60.0%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The Generator is the LLM inside the RAG to generate the answers.</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=60.00000000000001 class=\" progress-orange \">60.0%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">RETRIEVER</div>\n",
       "                    <div class=\"component-value tooltip  text-orange \">\n",
       "                        50.0%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The Retriever fetches relevant documents from the knowledge base according to a user query.</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=50.0 class=\" progress-orange \">50.0%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">REWRITER</div>\n",
       "                    <div class=\"component-value tooltip  text-red \">\n",
       "                        0.0%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The Rewriter modifies the user query to match a predefined format or to include the context from the chat history.</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=0.0 class=\" progress-red \">0.0%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">ROUTING</div>\n",
       "                    <div class=\"component-value tooltip  text-green \">\n",
       "                        100.0%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The Router filters the query of the user based on his intentions (intentions detection).</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=100.0 class=\" progress-green \">100.0%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">KNOWLEDGE_BASE</div>\n",
       "                    <div class=\"component-value tooltip  text-green \">\n",
       "                        83.33%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The knowledge base is the set of documents given to the RAG to generate the answers. Its scores is computed differently from the other components: it is the difference between the maximum and minimum correctness score across all the topics of the knowledge base.</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=83.33333333333334 class=\" progress-green \">83.33%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"overall-card\">\n",
       "                    <div class=\"overall-title\">Overall Correctness Score</div>\n",
       "                    <div class=\"overall-value\">60%</div>\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"section-card\">\n",
       "                <div class=\"section-title\">RECOMMENDATION</div>\n",
       "                <span class=\"section-content\">Focus on improving the RAG&#39;s ability to handle conversational, distracting, and double questions by enhancing the rewriter component role. Additionally, in order to improve domain-specific performance, bolster the knowledge base with more resources related to &#39;Artificial Intelligence Applications&#39;.</span>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"section-card\">\n",
       "                <div class=\"section-title\">CORRECTNESS BY TOPIC</div>\n",
       "                    <script type=\"text/javascript\">\n",
       "        (function() {\n",
       "  const fn = function() {\n",
       "    Bokeh.safely(function() {\n",
       "      (function(root) {\n",
       "        function embed_document(root) {\n",
       "        const docs_json = '{\"8a441dda-3bd4-4d9c-9e37-9ba9c0c16d12\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1190\",\"attributes\":{\"height\":350,\"width_policy\":\"max\",\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1192\",\"attributes\":{\"start\":0}},\"y_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1199\",\"attributes\":{\"factors\":[\"Artificial Intelligence Applications\",\"Artificial Intelligence and Machine Learning Education\",\"Others\"]}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1200\"},\"y_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1201\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1197\",\"attributes\":{\"text_color\":\"#E0E0E0\",\"text_font\":\"Helvetica\",\"text_font_size\":\"14pt\"}},\"outline_line_color\":\"#E0E0E0\",\"outline_line_alpha\":0.25,\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1219\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1187\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1188\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1189\"},\"data\":{\"type\":\"map\",\"entries\":[[\"correctness\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAASUCqqqqqqqpQQKqqqqqqqlBA\"},\"shape\":[3],\"dtype\":\"float64\",\"order\":\"little\"}],[\"metadata_values\",[\"Artificial Intelligence Applications\",\"Artificial Intelligence and Machine Learning Education\",\"Others\"]],[\"colors\",[\"#a50026\",\"#006837\",\"#006837\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1220\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1221\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1216\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_color\":{\"type\":\"value\",\"value\":\"#14191B\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1217\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"#14191B\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1218\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"#14191B\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1228\",\"attributes\":{\"data_source\":{\"id\":\"p1187\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1229\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1230\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1225\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"white\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#78BBFA\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1226\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"white\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#78BBFA\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1227\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"white\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#78BBFA\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1238\",\"attributes\":{\"visible\":false,\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1232\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1233\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1234\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[0]],[\"y\",[0]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1239\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1240\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1235\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#EA3829\",\"line_width\":2,\"line_dash\":[6]}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1236\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#EA3829\",\"line_alpha\":0.1,\"line_width\":2,\"line_dash\":[6]}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1237\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#EA3829\",\"line_alpha\":0.2,\"line_width\":2,\"line_dash\":[6]}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1198\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1212\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"topic\",\"@metadata_values\"],[\"Correctness\",\"@correctness{0.00}\"]]}}]}},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1207\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1208\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1209\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1210\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1202\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1203\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1204\"},\"axis_label\":\"Correctness (%)\",\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1205\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1206\",\"attributes\":{\"axis\":{\"id\":\"p1202\"},\"grid_line_color\":\"#E0E0E0\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1211\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1207\"},\"grid_line_color\":\"#E0E0E0\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Span\",\"id\":\"p1231\",\"attributes\":{\"location\":60.0,\"dimension\":\"height\",\"line_color\":\"#EA3829\",\"line_width\":2,\"line_dash\":[6]}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1241\",\"attributes\":{\"border_line_alpha\":0,\"background_fill_color\":\"#111516\",\"background_fill_alpha\":0.5,\"label_text_color\":\"#E0E0E0\",\"label_text_font\":\"Helvetica\",\"label_text_font_size\":\"1.025em\",\"label_standoff\":8,\"glyph_width\":15,\"spacing\":8,\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1242\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Correctness on the entire Testset\"},\"renderers\":[{\"id\":\"p1238\"}]}}]}}],\"background_fill_color\":\"#14191B\",\"border_fill_color\":\"#15191C\"}}]}}';\n",
       "        const render_items = [{\"docid\":\"8a441dda-3bd4-4d9c-9e37-9ba9c0c16d12\",\"roots\":{\"p1190\":\"e24558da-71b7-428c-bf74-1288792f9f22\"},\"root_ids\":[\"p1190\"]}];\n",
       "        root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "        }\n",
       "        if (root.Bokeh !== undefined) {\n",
       "          embed_document(root);\n",
       "        } else {\n",
       "          let attempts = 0;\n",
       "          const timer = setInterval(function(root) {\n",
       "            if (root.Bokeh !== undefined) {\n",
       "              clearInterval(timer);\n",
       "              embed_document(root);\n",
       "            } else {\n",
       "              attempts++;\n",
       "              if (attempts > 100) {\n",
       "                clearInterval(timer);\n",
       "                console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "              }\n",
       "            }\n",
       "          }, 10, root)\n",
       "        }\n",
       "      })(window);\n",
       "    });\n",
       "  };\n",
       "  if (document.readyState != \"loading\") fn();\n",
       "  else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "})();\n",
       "    </script>\n",
       "\n",
       "                <div id=\"e24558da-71b7-428c-bf74-1288792f9f22\" data-root-id=\"p1190\" style=\"display: contents;\"></div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"section-card\">\n",
       "                <div class=\"section-title\">KNOWLEDGE BASE OVERVIEW</div>\n",
       "                    <script type=\"text/javascript\">\n",
       "        (function() {\n",
       "  const fn = function() {\n",
       "    Bokeh.safely(function() {\n",
       "      (function(root) {\n",
       "        function embed_document(root) {\n",
       "        const docs_json = '{\"fd9ae6b0-6a02-4f1f-8895-da0344eb55db\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Tabs\",\"id\":\"p1121\",\"attributes\":{\"sizing_mode\":\"stretch_width\",\"tabs\":[{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"p1051\",\"attributes\":{\"title\":\"Topic exploration\",\"child\":{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1004\",\"attributes\":{\"sizing_mode\":\"stretch_width\",\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1013\",\"attributes\":{\"start\":10.378994607925415,\"end\":18.537613105773925}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1014\",\"attributes\":{\"start\":-0.05527853965759277,\"end\":7.278015613555908}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1015\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1016\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1011\",\"attributes\":{\"text_color\":\"#E0E0E0\",\"text_font\":\"Helvetica\",\"text_font_size\":\"14pt\"}},\"outline_line_color\":\"#E0E0E0\",\"outline_line_alpha\":0.25,\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1044\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1001\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1002\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1003\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"FBhJQZoGXkGHkkpBJQ9dQZm4X0Gxv1ZB+w9XQVEjdEG5gmpBDBpUQYgpQEEJBEBBosI6QfyiRUHliDpBxQlJQUgLREFhiDpBBQUqQY1ZZ0H4VCxBlwI4QcApM0GzTy5BBXljQUdwUkGAgFtBg7VvQYQiZ0HjmGRBiIFeQU1aUEHu9FFBHklxQTAiZEGJIXdByUBwQZTsWEEsInlBJHtLQQ==\"},\"shape\":[40],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"zFhcQKCwZUBlXIVAkd6zP7ibFED5+PY/P9QqQGbvOUClWSBA4GFBQIy1lECWAnpAh2xJQDJelT/6OhFAyrTjP4o1F0DDAco/6hxLQPV55j9RGIVAPq+SQBcQa0CTiR1A+JtOQJASeEDPT49AeEiPQJIRl0B5DrlAfiirQCJArkAL5ZtA7kagQJxcg0B7da9AZJlxQB3JwUAqmIZAMmgsQA==\"},\"shape\":[40],\"dtype\":\"float32\",\"order\":\"little\"}],[\"topic\",[\"Artificial Intelligence Applications\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Others\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Others\",\"Others\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Others\",\"Others\",\"Artificial Intelligence Applications\",\"Others\",\"Others\",\"Others\",\"Others\",\"Others\",\"Artificial Intelligence Applications\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Others\",\"Others\",\"Others\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Others\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Others\",\"Artificial Intelligence and Machine\\\\nLearning Education\",\"Artificial Intelligence Applications\"]],[\"id\",[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39]],[\"content\",[\"About Me | Abdul&#x27;s Portfolio DemoAbdul&#x27;s Portfolio DemoSearchCtrl\\\\u201a\\\\u00c4\\\\u00dc+\\\\u201a\\\\u00c4\\\\u00dcK\\\\uf8ff\\\\u00fc\\\\u00eb\\\\u00ae\\\\u201a\\\\u00c4\\\\u00e7\\\\uf8ff\\\\u00fc\\\\u00ed\\\\u00aaAbout MeProjects\\\\uf8ff\\\\u00fc\\\\u00ed\\\\u00baJobInsights: Streamlining Your Job Hunt with AI\\\\uf8ff\\\\u00fc\\\\u00e5\\\\u00eaWebChatAI\\\\uf8ff\\\\u00fc\\\\u00b4\\\\u00c4Chest-Cancer-Classification-Using-mlflow-and-DVC\\\\uf8ff\\\\u00fc\\\\u00ec\\\\u00e2CSVAnalystAI- Your AI Data analyst\\\\uf8ff\\\\u00fc\\\\u00ec\\\\u00d1Resume Screening Assistance\\\\uf8ff\\\\u00fc\\\\u00ec\\\\u00faScriptMaster AI\\\\u201e\\\\u00c4\\\\u03a9\\\\u00d4\\\\u220f\\\\u00e8Mini Projects Repository \\\\uf8ff\\\\u00fc\\\\u00f6\\\\u00c4About us\\\\uf8ff\\\\u00fc\\\\u00eb\\\\u00ae\\\\u201a\\\\u00c4\\\\u00e7\\\\uf8ff\\\\u00fc\\\\u00ed\\\\u00aaMore About MeVisionSkillsCertificationsthank\\\\uf8ff\\\\u00fc\\\\u00a7\\\\u00f9Thank You for Visiting My Portfolio!Powered by GitBook\\\\uf8ff\\\\u00fc\\\\u00eb\\\\u00ae\\\\u201a\\\\u00c4\\\\u00e7\\\\uf8ff\\\\u00fc\\\\u00ed\\\\u00aaAbout MeWHO AM I !Professiona...\",\"MLOps and LLMOps. Committed to utilizing AI for practical solutions and enhancing user experiences.Currently working as a Machine Learning intern at BrotoType.Keen interest in artificial intelligence, human-computer interaction, and related fields.Exploring MLOps, LLMs, Gen AI, and advanced NLP &amp; DL.Contact:   Socials linkedin discord leetcode instagramyoutubeCopy\",\"My skills\\\\u201a\\\\u00c4\\\\u00a2 Programming LanguagesPython, C , Java ,php\\\\u201a\\\\u00c4\\\\u00a2 Machine LearningSupervised &amp; Unsupervised Learning,Exploratory Data Analysis,Data PreprocessingFeature Engineering\\\\u201a\\\\u00c4\\\\u00a2Natural Language Processing\\\\u201a\\\\u00c4\\\\u00a2Deep LearningCNN, RNN, Generative AI, GAN, Transformers, Transfer Learning, Large Language Models,Stable Diffusion Model\\\\u201a\\\\u00c4\\\\u00a2DatabasesPostgreSQL, Vector Database\\\\u201a\\\\u00c4\\\\u00a2Version ControlGit , GitHub , DVC\\\\u201a\\\\u00c4\\\\u00a2DeploymentAWS, Huggingface, Streamlit\\\\u201a\\\\u00c4\\\\u00a2Data Structures &amp; Algorithms\\\\u201a\\\\u00c4\\\\u00a2Statistics and Probabilit...\",\"Streamlining Your Job Hunt with AIIn today&#x27;s competitive job market, finding the right opportunity can be challenging. Job seekers often spend hours scouring through job listings, optimizing their resumes, and crafting personalized cover letters. However, what if there was a way to simplify this process and gain a competitive edge?JobInsights is an innovative AI-powered application designed to revolutionize the job hunting experience. By leveraging cutting-edge technologies, JobInsights aggregat...\",\"to offer various features and strategies to secure job interviews and succeed in them, saving significant time by eliminating the need for manual work.FeaturesData Extraction: Extract real-time job information from popular websites.Understand the Job Market: Gain insights into the real-time job market through trend analysis and visualizations.AI Conversation: A general assistant that summarizes job requirements and answers general queries.RAG AI System: A specialized assistant that responds by c...\",\"reach out to potential employers.Future DevelopmentsJobInsights is continuously evolving to offer more exciting features, including:Building resumes from raw text or portfolios that match real-time job requirements.AI-driven interview preparation using resumes and real-time job requirements for specific job roles.AI for preparing learning materials and interview preparation.TechnologiesJobInsights is built using Python and incorporates specialized scraping libraries for data extraction. The user...\",\"feel free to open a pull request or an issue on the GitHub repository.LicenseThis project is licensed under the MIT License.ConclusionWith JobInsights, the job hunting process is no longer a daunting task. By leveraging the power of AI and real-time data analysis, job seekers can streamline their job search, optimize their resumes, and secure their dream job. Try JobInsights today and take the first step towards a successful career!projects 2 ---------------------------------------------------Go...\",\"web scraping.The ChallengeLLMs, while powerful, have a finite understanding of the world. They lack real-time information, which can be crucial in dynamic conversations. For instance, an LLM might not have the latest news, product updates, or local events, limiting its ability to provide relevant and up-to-date responses.The SolutionWebChatAI addresses this challenge by scraping the web for information in real-time. When faced with a query that falls outside its pre-existing knowledge base, WebC...\",\"related to the query.Response Generation: Based on the information gathered, WebChatAI generates a response that is relevant and up-to-date.Key FeaturesReal-time Information: By scraping the web, WebChatAI ensures that its responses are based on the latest information available.Enhanced Accuracy: With access to real-time data, WebChatAI&#x27;s responses are more accurate and relevant.Dynamic Learning: WebChatAI can use the information gathered from web scraping to improve its knowledge base over time...\",\"or finding local businesses.ConclusionWebChatAI&#x27;s ability to scrape the web for real-time information sets it apart from traditional LLMs. By combining the power of AI with web scraping, WebChatAI offers a more dynamic and accurate conversational experience, making it a valuable tool for businesses and individuals alike.projects 3 ---------------------------------------------------Tutorial will come soon...Chest-Cancer-Classification-Using-mlflow-and-DVCIntroductionThe project focuses on develop...\",\"ensuring it is in a suitable format for the deep learning model.Model Training: Train the deep learning model on the preprocessed data to predict breast cancer risk and subtype.Model Evaluation: Evaluate the trained model&#x27;s performance using metrics such as accuracy and loss.Model Deployment: Deploy the trained model to make predictions on new chest CT scan images.Training PipelineThe training pipeline includes updating various configuration files, such as schema.yaml and params.yaml, to ensure ...\",\"cd Chest-Cancer-Classification-Using-mlflow-and-DVCSet up a conda environment:Copyconda create -n ML_project python=3.10 -y\",\"conda activate ML_projectRun the application:Copypython app.pyConclusionIn conclusion, the Chest-Cancer-Classification-Using-mlflow-and-DVC project aims to leverage deep learning and DevOps practices to improve breast cancer prediction and subtype classification, ultimately leading to better patient outcomes.Project 4 ---------------------------------------------------------Let&#x27;s get started!CSVAnalystAI: Streamlining Data Interaction with AIIn today&#x27;s data-driven world, extracting meaningful in...\",\"how users interact with their CSV data. By leveraging advanced AI technologies, the application enables users to ask questions in natural language, generate insightful visualizations, and automatically summarize their data. This blog delves into the features, techniques, and technologies that power CSVAnalystAI, making data analysis accessible to everyone.Features1. Chat with CSVOne of the standout features of CSVAnalystAI is the ability to interact with your CSV data through natural language qu...\",\"based on the CSV data.Streamlit: For creating an interactive and user-friendly interface.2. Chat and Visualize with CSVIn addition to answering queries, CSVAnalystAI can generate visualizations based on user queries. Whether you need a bar chart, line graph, or pie chart, the application can create it on the fly. For instance, you can ask, \\\\\"Show me a bar chart of monthly sales,\\\\\" and CSVAnalystAI will generate the corresponding visualization.Technologies Used:LangChain Agents: To manage data inte...\",\"users who need to understand large datasets without diving into the details.Technologies Used:AI and Machine Learning Algorithms: For summarizing data and identifying key trends.Natural Language Generation (NLG): To create human-readable summaries.Microsoft&#x27;s Open Source Library - Lida: For creating dynamic and interactive visualizations.Streamlit: To display summaries and insights in an intuitive format.4. Additional FeaturesCSVAnalystAI is continually evolving, with plans to introduce more exc...\",\"Streamlit allows developers to create responsive user interfaces quickly. The integration with other libraries and technologies makes it an ideal choice for developing data-centric applications like CSVAnalystAI.GPT-3.5Large language models like GPT-3.5 are used to understand and interpret user queries. These models are trained on vast amounts of text data, allowing them to understand natural language and provide coherent and contextually relevant answers. GPT-3.5 plays a crucial role in both th...\",\"and customization options, enabling CSVAnalystAI to generate visualizations that meet the specific needs of users. The integration of Lida with Streamlit ensures that visualizations are seamlessly rendered within the web application.ConclusionCSVAnalystAI is a groundbreaking application that simplifies data interaction and analysis. By leveraging advanced AI techniques, natural language processing, and powerful visualization libraries, it provides users with an intuitive and efficient way to exp...\",\"Develop a real estate price prediction website using sklearn and linear regression with the Bangalore home prices dataset from Kaggle. Includes EDA, data cleaning, outlier detection, feature engineering, dimensionality reduction, hyperparameter tuning, k-fold cross-validation, Python Flask server, and a website with HTML/CSS/JavaScript. Predicts real estate prices based on user-input home details. Tech: Python, Numpy, Pandas, Matplotlib, Sklearn, Flask. Repo: https://github.com/samad-ms/bengalur...\",\"Features: Offers templates for various job-related emails, enabling users to customize the email topic, sender name, recipient name, writing style, and signature. Its interactive interface simplifies email generation, and it uses the OpenAI GPT-3.5 Turbo model to generate responses based on user inputs.\",\"Technologies: Python, OpenAI, LangChain, Streamlit.repo: https://github.com/samad-ms/EmailSparkAI5. Sentiment Analysis on IMDBDescription: This project involves training a logistic regression model to perform sentiment analysis on the IMDB dataset. It demonstrates various data science and machine learning techniques, including data preparation, feature extraction using TF-IDF, model training, evaluation, and tracking experiments with MLflow.Features: Splits data into training and test sets while...\",\"TF-IDF.repo: https://github.com/samad-ms/sentiment_analysis_with_dvc6.Fine-Tuning Llama 2 with QLoRADescription: This project focuses on fine-tuning the Llama 2 model using Quantized Low Rank Adaptation (QLoRA) in a Google Colab environment. The goal is to efficiently adapt large language models to specific tasks with minimal resource usage. Technologies: Python, QLoRA, Google Colab, Transformers, PyTorch, Hugging Face Datasets, BitsAndBytes. repo:https://github.com/samad-ms/Fine_Tune_Llama_27.M...\",\"software systems.) repo:https://github.com/samad-ms/Mnist_classification_with_hydra8.Fire Weather Index (FWI) PredictionDescription: Predicting the Fire Weather Index (FWI) using Ridge Regression. This model utilizes features like Temperature, RH, Ws, Rain, FFMC, DMC, DC, ISI, BUI, FWI, Classes, and Region. Ridge Regression is chosen for its ability to handle multicollinearity.Technologies: Python, Ridge Regression. repo: https://github.com/samad-ms/fwipredictor9. Chest Cancer Classification Pro...\",\"ML Classification ProjectDescription: This project aims to predict diabetes based on health data, including features like pregnancies, glucose, blood pressure, and more. It involves data preprocessing, exploratory data analysis, model selection (Logistic Regression), and model deployment. repo : https://github.com/samad-ms/Diabetes-Prediction11. CsvAnalytistAIDescription: Streamlit application designed to help users interact with their CSV data through natural language queries and generate visua...\",\"is to become a renowned expert in artificial intelligence and machine learning, pioneering groundbreaking solutions that redefine the capabilities of AI. I aim to drive significant advancements in the field, inspiring others to push the boundaries of what is possible in technology and beyond. Additionally, I want to contribute to open-source projects and give back to the community by providing tutorials and guidance on effective contributions, empowering others to make a positive impact through ...\",\"and applying new technologies, methodologies, and best practices. My focus is on leveraging AI and machine learning to create practical solutions that have a positive impact on society, prioritizing projects that address pressing issues such as healthcare, sustainability, and education, aiming to develop innovative and sustainable solutions. Additionally, I am dedicated to promoting diversity and inclusion in the AI field, ensuring that the benefits of AI are accessible to all and that its devel...\",\"Streamlit\\\\u201a\\\\u00c4\\\\u00a2Data Structures &amp; Algorithms\\\\u201a\\\\u00c4\\\\u00a2Statistics and Probability\\\\u201a\\\\u00c4\\\\u00a2Frameworks &amp; LibrariesNumPy, Pandas, scikit-learn, Matplotlib, Seaborn,Plotly ,spaCy,NLTK ,PyTorch, TensorFlow, Keras, OpenCV,MLOps tools,MLflow,Docker,hydraLangchain, Huggingface Transformers,OllamaFastAPI, Flask\\\\u201a\\\\u00c4\\\\u00a2PlatformsKaggle, Google Colab\\\\u201a\\\\u00c4\\\\u00a2Familiar withDocker, DVC,CI/CD Pipelines ,C++, Java________________________________________________________________________________________1) A Deep Understanding of Deep Learning ...\",\"chunks, which made grasping the material much easier. The hands-on projects were the highlight for me. They not only reinforced the theoretical concepts but also provided valuable practical experience.One of the things I found particularly valuable was the way the course is structured. It starts with the basics and gradually builds up to more advanced topics. This approach really helped me grasp the fundamentals before moving on to more complex ideas.Overall, I would rate Mike X Cohen&#x27;s deep lea...\",\"with AWS\\\\\" seemed like a promising course, but unfortunately, it didn&#x27;t meet my expectations. Despite the comprehensive coverage of MLOps concepts and practical implementation using AWS, I found that the course fell short in certain areas.While the course did offer a structured learning path and hands-on projects, I felt that some of the explanations were not as clear as I had hoped. Additionally, there were times when the course content seemed a bit outdated, which was disappointing.On the posit...\",\"it may fall short.________________________________________________________________________________________3)  Python for Beginners - linkI recently completed the \\\\\"Python Programming, OOP in Python, Database connectivity, Web Development using Python\\\\\" course on Udemy, and I found it to be an excellent resource for beginners looking to learn Python and its various applications. I would rate it 4.5 out of 5 for its comprehensive coverage of Python fundamentals and practical examples.The course cove...\",\"building real-world applications, which helps reinforce your understanding of the concepts and prepares you for practical use. The course also includes quizzes and assignments to test your knowledge and reinforce your learning.The section on web development using Django, a high-level web framework for Python, was particularly valuable. Django is used by companies like Google, YouTube, and NASA, making it a valuable skill for aspiring web developers. The course covers the basics of Django and pro...\",\"Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow by AI Sciences - link - websiteI recently completed the \\\\\"Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.\\\\\" course on Udemy, and it was by far my favorite course on the platform. I would rate it 5/5 for its depth of knowledge and comprehensive coverage of computer vision concepts.The course, rated 4.5 out of 5, is designed for...\",\"projects, such as change detection in CCTV cameras and smart DVRs, which help reinforce learning and build practical skills.The course covers a wide range of topics, including image transformations, image filtering and morphology, shape detection, key point detection and matching, motion analysis, object detection, and 3D computer vision. Each topic is explained in detail, with clear explanations and examples.Overall, I highly recommend the \\\\\"Computer Vision-Become an ace of Computer Vision, Comp...\",\"- link I recently completed the \\\\\"From the Basics of LLMs to Production-Grade Microservice Architecture with Kubernetes\\\\\" course on Udemy, and it was an incredibly informative and practical learning experience. The course, rated 4.5 out of 5, is designed to provide a comprehensive understanding of LangChain, a framework crucial for developing generative AI applications.The course starts with the basics, such as the basic usage of the OpenAI API, and gradually progresses to more advanced topics, in...\",\"topics like Hybrid Search, Indexing API, and LangSmith, highlighting their importance in enhancing the efficiency and functionality of AI applications. Additionally, the course integrates theory with practical skills, introducing Microservice Architecture in large language model (LLM) applications and the LangChain Expression Language.Overall, I found the \\\\\"From the Basics of LLMs to Production-Grade Microservice Architecture with Kubernetes\\\\\" course to be highly valuable for anyone looking to dee...\",\"I recently completed the \\\\\"Understand Generative AI, Prompt Engineering, Huggingface-Models, LLMs, Vector Databases, RAG, OpenAI, Claude, Llama2\\\\\" course on Udemy, and it was a highly enriching experience. The course, rated 4.5 out of 5, is designed for both beginners and seasoned professionals in the field of Natural Language Processing (NLP) and Generative AI.The course covers a wide range of topics, starting with an introduction to NLP and its fundamental principles. I particularly enjoyed the ...\",\"course also delves into advanced topics such as prompt engineering, retrieval-augmented generation (RAG), and working with OpenAI&#x27;s ChatGPT API. These sections were incredibly insightful, offering practical strategies and techniques for improving the performance of NLP models.The course culminates in a capstone project where students create a chatbot to interact with a PDF document, demonstrating the real-world application of the skills learned throughout the course.Overall, I found the \\\\\"Underst...\",\"Intelligence, Deep Learning, Machine Learning, and Data Science in Python\\\\\" course with high hopes, considering its impressive rating of 4.8 out of 5. The course offers a comprehensive 4-in-1 approach, covering vector models, text preprocessing, probability models, Markov models, machine learning, and deep learning methods in NLP.In the first part, which focuses on vector models and text preprocessing, I appreciated the detailed explanations on converting text into vectors using techniques like C...\",\"machine learning methods, provided a good overview of classic NLP tasks such as spam detection, sentiment analysis, and topic modeling. The application-focused approach was helpful, but I wished there was more emphasis on the underlying algorithms.The fourth part, focusing on deep learning methods, was perhaps the most engaging. I appreciated learning about modern neural network architectures like CNNs, RNNs, LSTM, and GRU, which are essential for understanding advanced AI models.Overall, while ...\",\"skillsprojects 1 ---------------------------------------------------JobInsights: Streamlining Your Job Hunt with AIprojects 2 ---------------------------------------------------projects 3 ---------------------------------------------------Project 4 ---------------------------------------------------------CSVAnalystAI: Streamlining Data Interaction with AIOverviewFeaturesTechniques and TechnologiesConclusionMINI PROJECTS -------------------------------------------------Projects Overview \\\\uf8ff\\\\u00fc\\\\u00ec\\\\u00f9My Vi...\"]],[\"color\",{\"type\":\"ndarray\",\"array\":[\"#1f77b4\",\"#aec7e8\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#999\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#999\",\"#999\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#999\",\"#999\",\"#1f77b4\",\"#999\",\"#999\",\"#999\",\"#999\",\"#999\",\"#1f77b4\",\"#aec7e8\",\"#aec7e8\",\"#aec7e8\",\"#999\",\"#999\",\"#999\",\"#aec7e8\",\"#aec7e8\",\"#aec7e8\",\"#999\",\"#aec7e8\",\"#999\",\"#aec7e8\",\"#1f77b4\"],\"shape\":[40],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1045\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1046\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1041\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1042\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1043\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1012\",\"attributes\":{\"logo\":\"grey\",\"tools\":[{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1027\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":\"\\\\n    &lt;div style=\\\\\"width:400px;\\\\\"&gt;\\\\n    &lt;b&gt;Document id:&lt;/b&gt; @id &lt;br&gt;\\\\n    &lt;b&gt;Topic:&lt;/b&gt; @topic &lt;br&gt;\\\\n    &lt;b&gt;Document Content:&lt;/b&gt; @content\\\\n    &lt;/div&gt;\\\\n    \"}},{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1028\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1029\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1030\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1031\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1036\"},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1037\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1022\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1023\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1024\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1025\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1017\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1018\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1019\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1020\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1021\",\"attributes\":{\"axis\":{\"id\":\"p1017\"},\"grid_line_color\":\"white\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1026\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1022\"},\"grid_line_color\":\"white\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1047\",\"attributes\":{\"title\":\"Knowledge Base Tospics\",\"title_text_color\":\"#B1B1B1\",\"title_text_font_style\":\"bold\",\"border_line_alpha\":0,\"background_fill_color\":\"#111516\",\"background_fill_alpha\":0.5,\"label_text_color\":\"#E0E0E0\",\"label_text_font\":\"Helvetica\",\"label_text_font_size\":\"1.025em\",\"label_standoff\":8,\"glyph_width\":15,\"spacing\":8,\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1048\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Artificial Intelligence Applications\"},\"renderers\":[{\"id\":\"p1044\"}],\"index\":0}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1049\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Artificial Intelligence and Machine\\\\nLearning Education\"},\"renderers\":[{\"id\":\"p1044\"}],\"index\":1}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1050\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Others\"},\"renderers\":[{\"id\":\"p1044\"}],\"index\":7}}]}}],\"background_fill_color\":\"#14191B\",\"border_fill_color\":\"#15191C\"}}}},{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"p1120\",\"attributes\":{\"title\":\"Failures\",\"child\":{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1056\",\"attributes\":{\"sizing_mode\":\"stretch_width\",\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1065\",\"attributes\":{\"start\":10.378994607925415,\"end\":18.537613105773925}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1066\",\"attributes\":{\"start\":-0.05527853965759277,\"end\":7.278015613555908}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1067\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1068\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1063\",\"attributes\":{\"text_color\":\"#E0E0E0\",\"text_font\":\"Helvetica\",\"text_font_size\":\"14pt\"}},\"outline_line_color\":\"#E0E0E0\",\"outline_line_alpha\":0.25,\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1095\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1052\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1053\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1054\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"DBpUQU1aUEEFeWNBhCJnQYeSSkEke0tBDBpUQclAcEGU7FhB7vRRQQ==\"},\"shape\":[10],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"4GFBQCJArkD4m05AkhGXQGVchUAyaCxA4GFBQGSZcUAdycFAC+WbQA==\"},\"shape\":[10],\"dtype\":\"float32\",\"order\":\"little\"}],[\"topic\",[\"Artificial Intelligence Applications\",\"Others\",\"Others\",\"Artificial Intelligence and Machine Learning Education\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Artificial Intelligence Applications\",\"Artificial Intelligence and Machine Learning Education\",\"Others\",\"Artificial Intelligence and Machine Learning Education\"]],[\"correctness\",[true,true,true,true,false,false,true,true,false,false]],[\"questions\",[\"What is the aim of the Chest-Cancer-Classification-Using-mlflow-and-DVC project?\",\"What topics does the &#x27;Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.&#x27; course cover?\",\"What are the main competencies Abdul Samad possesses in the domain of artificial intelligence and machine learning, and how does he apply these skills in his work?\",\"What score did the reviewer assign to the course titled &#x27;Mastering MLOps with AWS&#x27; in their overall assessment?\",\"Considering Abdul Samad&#x27;s proficiency in Python, C, Java, and PHP, is he a suitable candidate for a role that involves working with AI technologies like GPT-3.5-turbo, Gemini, LIDA (Microsoft), and LangChain?\",\"Considering Abdul Samad&#x27;s proficiency in Python, Java, and PHP, can you list some of the projects he has worked on using these programming languages?\",\"As a startup owner looking for potential collaborations, I&#x27;m interested in how Abdul Samad&#x27;s project, WebChatAI, ensures the accuracy and relevance of its responses. Can you explain?\",\"Hi, I&#x27;m really interested in Abdul Samad&#x27;s educational background. Could you tell me what the final project was for the &#x27;Understand Generative AI, Prompt Engineering, Huggingface-Models, LLMs, Vector Databases, RAG, OpenAI, Claude, Llama2&#x27; course that he completed?\",\"What is the rating of the &#x27;Intelligence, Deep Learning, Machine Learning, and Data Science in Python&#x27; course and what are the four main areas it covers?\",\"What is its rating?\"]],[\"agent_answer\",[\"The aim of the Chest-Cancer-Classification-Using-mlflow-and-DVC project is to leverage deep learning and DevOps practices to improve breast cancer prediction and subtype classification, ultimately leading to better patient outcomes.\",\"The &#x27;Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.&#x27; course covers a wide range of topics including image transformations, image filtering and morphology, shape detection, key point detection and matching, motion analysis, object detection, and 3D computer vision.\",\"Abdul Samad possesses competencies in Python, Machine Learning, Deep Learning, NLP, computer vision, generative AI, and databases such as PostgreSQL and Vector Database. He applies these skills in developing practical solutions that address pressing issues in society like healthcare, sustainability, and education. Additionally, he focuses on leveraging AI and machine learning to create innovative and sustainable solutions while promoting diversity and inclusion in the AI field.\",\"The reviewer assigned a score of 3/5 to the course titled &#x27;Mastering MLOps with AWS&#x27; in their overall assessment.\",\"Based on the information provided, Abdul Samad&#x27;s proficiency in Python, C, Java, and PHP makes him a suitable candidate for a role that involves working with AI technologies like GPT-3.5-turbo, Gemini, LIDA (Microsoft), and LangChain.\",\"I don&#x27;t know.\",\"WebChatAI ensures the accuracy and relevance of its responses by scraping the web for real-time information. This allows the AI to provide up-to-date and accurate responses based on the latest available data. Additionally, WebChatAI constantly learns and improves its knowledge base over time through dynamic learning, ensuring that it stays relevant and up-to-date.\",\"The final project for the &#x27;Understand Generative AI, Prompt Engineering, Huggingface-Models, LLMs, Vector Databases, RAG, OpenAI, Claude, Llama2&#x27; course that Abdul Samad completed was creating a chatbot to interact with a PDF document.\",\"The rating of the &#x27;Intelligence, Deep Learning, Machine Learning, and Data Science in Python&#x27; course is 4.8 out of 5. The four main areas it covers are vector models, text preprocessing, probability models, and deep learning methods in NLP.\",\"The document does not specify the rating of \\\\\"its.\\\\\"\"]],[\"reference_answer\",[\"The project focuses on developing a deep learning model for predicting breast cancer risk and subtype, specifically adenocarcinoma, using chest CT scan images. This model aims to improve early detection and diagnosis, leading to more personalized treatment strategies.\",\"The course covers a wide range of topics, including image transformations, image filtering and morphology, shape detection, key point detection and matching, motion analysis, object detection, and 3D computer vision.\",\"Abdul Samad&#x27;s key skills in machine learning and AI include Programming Languages like Python, C , Java ,php, Supervised &amp; Unsupervised Learning, Exploratory Data Analysis, Data Preprocessing, Feature Engineering, Natural Language Processing, Deep Learning techniques such as CNN, RNN, Generative AI, GAN, Transformers, Transfer Learning, Large Language Models, Stable Diffusion Model, Databases like PostgreSQL, Vector Database, Version Control tools like Git , GitHub , DVC, and Deployment tools like AWS, Huggingface, Streamlit.\",\"The reviewer rated the &#x27;Mastering MLOps with AWS&#x27; course a 3/5.\",\"Abdul Samad is proficient in Python, C, Java, and PHP.\",\"Abdul Samad has worked on projects like &#x27;JobInsights: Streamlining Your Job Hunt with AI&#x27;, &#x27;CSVAnalystAI: Streamlining Data Interaction with AI&#x27;, &#x27;WebChatAI&#x27; and &#x27;CsvAnalistAI&#x27;.\",\"WebChatAI maintains the accuracy and relevance of its responses by scraping the web for information in real-time. When faced with a query that falls outside its pre-existing knowledge base, WebChatAI dynamically searches the web for relevant information.\",\"The final project in the &#x27;Understand Generative AI, Prompt Engineering, Huggingface-Models, LLMs, Vector Databases, RAG, OpenAI, Claude, Llama2&#x27; course is a capstone project where students create a chatbot to interact with a PDF document.\",\"The course has a rating of 4.8 out of 5 and it covers vector models and text preprocessing, probability models and Markov models, machine learning methods, and deep learning methods in NLP.\",\"The course is rated 4.5 out of 5.\"]],[\"id\",[9,31,24,28,2,39,9,36,37,32]],[\"content\",[\"or finding local businesses.ConclusionWebChatAI&#x27;s ability to scrape the web for real-time information sets it apart from traditional LLMs. By combining the power of AI with web scraping, WebChatAI offers a more dynamic and accurate conversational experience, making it a valuable tool for businesses and individuals alike.projects 3 ---------------------------------------------------Tutorial will come soon...Chest-Cancer-Classification-Using-mlflow-and-DVCIntroductionThe project focuses on develop...\",\"Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow by AI Sciences - link - websiteI recently completed the \\\\\"Computer Vision-Become an ace of Computer Vision, Computer Vision for Apps using Python, OpenCV, TensorFlow, etc.\\\\\" course on Udemy, and it was by far my favorite course on the platform. I would rate it 5/5 for its depth of knowledge and comprehensive coverage of computer vision concepts.The course, rated 4.5 out of 5, is designed for...\",\"is to become a renowned expert in artificial intelligence and machine learning, pioneering groundbreaking solutions that redefine the capabilities of AI. I aim to drive significant advancements in the field, inspiring others to push the boundaries of what is possible in technology and beyond. Additionally, I want to contribute to open-source projects and give back to the community by providing tutorials and guidance on effective contributions, empowering others to make a positive impact through ...\",\"with AWS\\\\\" seemed like a promising course, but unfortunately, it didn&#x27;t meet my expectations. Despite the comprehensive coverage of MLOps concepts and practical implementation using AWS, I found that the course fell short in certain areas.While the course did offer a structured learning path and hands-on projects, I felt that some of the explanations were not as clear as I had hoped. Additionally, there were times when the course content seemed a bit outdated, which was disappointing.On the posit...\",\"My skills\\\\u201a\\\\u00c4\\\\u00a2 Programming LanguagesPython, C , Java ,php\\\\u201a\\\\u00c4\\\\u00a2 Machine LearningSupervised &amp; Unsupervised Learning,Exploratory Data Analysis,Data PreprocessingFeature Engineering\\\\u201a\\\\u00c4\\\\u00a2Natural Language Processing\\\\u201a\\\\u00c4\\\\u00a2Deep LearningCNN, RNN, Generative AI, GAN, Transformers, Transfer Learning, Large Language Models,Stable Diffusion Model\\\\u201a\\\\u00c4\\\\u00a2DatabasesPostgreSQL, Vector Database\\\\u201a\\\\u00c4\\\\u00a2Version ControlGit , GitHub , DVC\\\\u201a\\\\u00c4\\\\u00a2DeploymentAWS, Huggingface, Streamlit\\\\u201a\\\\u00c4\\\\u00a2Data Structures &amp; Algorithms\\\\u201a\\\\u00c4\\\\u00a2Statistics and Probabilit...\",\"skillsprojects 1 ---------------------------------------------------JobInsights: Streamlining Your Job Hunt with AIprojects 2 ---------------------------------------------------projects 3 ---------------------------------------------------Project 4 ---------------------------------------------------------CSVAnalystAI: Streamlining Data Interaction with AIOverviewFeaturesTechniques and TechnologiesConclusionMINI PROJECTS -------------------------------------------------Projects Overview \\\\uf8ff\\\\u00fc\\\\u00ec\\\\u00f9My Vi...\",\"or finding local businesses.ConclusionWebChatAI&#x27;s ability to scrape the web for real-time information sets it apart from traditional LLMs. By combining the power of AI with web scraping, WebChatAI offers a more dynamic and accurate conversational experience, making it a valuable tool for businesses and individuals alike.projects 3 ---------------------------------------------------Tutorial will come soon...Chest-Cancer-Classification-Using-mlflow-and-DVCIntroductionThe project focuses on develop...\",\"course also delves into advanced topics such as prompt engineering, retrieval-augmented generation (RAG), and working with OpenAI&#x27;s ChatGPT API. These sections were incredibly insightful, offering practical strategies and techniques for improving the performance of NLP models.The course culminates in a capstone project where students create a chatbot to interact with a PDF document, demonstrating the real-world application of the skills learned throughout the course.Overall, I found the \\\\\"Underst...\",\"Intelligence, Deep Learning, Machine Learning, and Data Science in Python\\\\\" course with high hopes, considering its impressive rating of 4.8 out of 5. The course offers a comprehensive 4-in-1 approach, covering vector models, text preprocessing, probability models, Markov models, machine learning, and deep learning methods in NLP.In the first part, which focuses on vector models and text preprocessing, I appreciated the detailed explanations on converting text into vectors using techniques like C...\",\"projects, such as change detection in CCTV cameras and smart DVRs, which help reinforce learning and build practical skills.The course covers a wide range of topics, including image transformations, image filtering and morphology, shape detection, key point detection and matching, motion analysis, object detection, and 3D computer vision. Each topic is explained in detail, with clear explanations and examples.Overall, I highly recommend the \\\\\"Computer Vision-Become an ace of Computer Vision, Comp...\"]],[\"color\",[\"#0a980a\",\"#0a980a\",\"#0a980a\",\"#0a980a\",\"#ba0e0e\",\"#ba0e0e\",\"#0a980a\",\"#0a980a\",\"#ba0e0e\",\"#ba0e0e\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1096\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1097\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1092\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1093\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1094\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1110\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1101\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1102\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1103\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"FBhJQZoGXkGHkkpBJQ9dQZm4X0Gxv1ZB+w9XQVEjdEG5gmpBDBpUQYgpQEEJBEBBosI6QfyiRUHliDpBxQlJQUgLREFhiDpBBQUqQY1ZZ0H4VCxBlwI4QcApM0GzTy5BBXljQUdwUkGAgFtBg7VvQYQiZ0HjmGRBiIFeQU1aUEHu9FFBHklxQTAiZEGJIXdByUBwQZTsWEEsInlBJHtLQQ==\"},\"shape\":[40],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"zFhcQKCwZUBlXIVAkd6zP7ibFED5+PY/P9QqQGbvOUClWSBA4GFBQIy1lECWAnpAh2xJQDJelT/6OhFAyrTjP4o1F0DDAco/6hxLQPV55j9RGIVAPq+SQBcQa0CTiR1A+JtOQJASeEDPT49AeEiPQJIRl0B5DrlAfiirQCJArkAL5ZtA7kagQJxcg0B7da9AZJlxQB3JwUAqmIZAMmgsQA==\"},\"shape\":[40],\"dtype\":\"float32\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1111\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1112\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1107\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"value\",\"value\":\"grey\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"grey\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1108\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"value\",\"value\":\"grey\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"value\",\"value\":\"grey\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1109\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"value\",\"value\":\"grey\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"grey\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1064\",\"attributes\":{\"logo\":\"grey\",\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1079\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1080\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1081\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1082\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1087\"},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1088\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1055\",\"attributes\":{\"renderers\":[{\"id\":\"p1095\"}],\"tooltips\":\"\\\\n    &lt;div style=\\\\\"width:400px;\\\\\"&gt;\\\\n    &lt;b&gt;Document id:&lt;/b&gt; @id &lt;br&gt;\\\\n    &lt;b&gt;Topic:&lt;/b&gt; @topic &lt;br&gt;\\\\n    &lt;b&gt;Question:&lt;/b&gt; @questions &lt;br&gt;\\\\n    &lt;b&gt;agent Answer:&lt;/b&gt; @agent_answer &lt;br&gt;\\\\n    &lt;b&gt;Reference Answer:&lt;/b&gt; @reference_answer &lt;br&gt;\\\\n    &lt;b&gt;Correctness:&lt;/b&gt; @correctness &lt;br&gt;\\\\n    &lt;b&gt;Content:&lt;/b&gt; @content\\\\n    &lt;/div&gt;\\\\n    \"}}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1074\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1075\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1076\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1077\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1069\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1070\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1071\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1072\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1073\",\"attributes\":{\"axis\":{\"id\":\"p1069\"},\"grid_line_color\":\"white\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1078\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1074\"},\"grid_line_color\":\"white\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1098\",\"attributes\":{\"title\":\"Question Correctness\",\"title_text_color\":\"#B1B1B1\",\"title_text_font_style\":\"bold\",\"border_line_alpha\":0,\"background_fill_color\":\"#111516\",\"background_fill_alpha\":0.5,\"label_text_color\":\"#E0E0E0\",\"label_text_font\":\"Helvetica\",\"label_text_font_size\":\"1.025em\",\"label_standoff\":8,\"glyph_width\":15,\"spacing\":8,\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1099\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"False\"},\"renderers\":[{\"id\":\"p1095\"}],\"index\":4}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1100\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"True\"},\"renderers\":[{\"id\":\"p1095\"}],\"index\":0}}]}},{\"type\":\"object\",\"name\":\"LabelSet\",\"id\":\"p1116\",\"attributes\":{\"level\":\"glyph\",\"source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1113\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1114\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1115\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"855QQbQ8Z0E=\"},\"shape\":[2],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"kzEzQC1+i0A=\"},\"shape\":[2],\"dtype\":\"float32\",\"order\":\"little\"}],[\"topic\",[\"Artificial Intelligence Applications\",\"Artificial Intelligence and Machine Learning Education\"]]]}}},\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"text\":{\"type\":\"field\",\"field\":\"topic\"},\"text_color\":{\"type\":\"value\",\"value\":\"#B1B1B1\"},\"text_font_size\":{\"type\":\"value\",\"value\":\"12pt\"},\"text_font_style\":{\"type\":\"value\",\"value\":\"bold\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"}}}],\"background_fill_color\":\"#14191B\",\"border_fill_color\":\"#15191C\"}}}}],\"tabs_location\":\"below\"}}]}}';\n",
       "        const render_items = [{\"docid\":\"fd9ae6b0-6a02-4f1f-8895-da0344eb55db\",\"roots\":{\"p1121\":\"a5dc1166-569d-4129-a357-fd3ca33329b4\"},\"root_ids\":[\"p1121\"]}];\n",
       "        root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "        }\n",
       "        if (root.Bokeh !== undefined) {\n",
       "          embed_document(root);\n",
       "        } else {\n",
       "          let attempts = 0;\n",
       "          const timer = setInterval(function(root) {\n",
       "            if (root.Bokeh !== undefined) {\n",
       "              clearInterval(timer);\n",
       "              embed_document(root);\n",
       "            } else {\n",
       "              attempts++;\n",
       "              if (attempts > 100) {\n",
       "                clearInterval(timer);\n",
       "                console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "              }\n",
       "            }\n",
       "          }, 10, root)\n",
       "        }\n",
       "      })(window);\n",
       "    });\n",
       "  };\n",
       "  if (document.readyState != \"loading\") fn();\n",
       "  else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "})();\n",
       "    </script>\n",
       "\n",
       "                <div id=\"a5dc1166-569d-4129-a357-fd3ca33329b4\" data-root-id=\"p1121\" style=\"display: contents;\"></div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"section-card\">\n",
       "\n",
       "                <div class=\"section-title\">SELECTED METRICS</div>\n",
       "\n",
       "                \n",
       "\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "    </div>\n",
       "</div>\n",
       "\n",
       "\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "    function opentab(evt, name) {\n",
       "    // Declare all variables\n",
       "    let i, tabcontent, tablinks;\n",
       "\n",
       "    // Get all elements with class=\"tabcontent\" and hide them\n",
       "    tabcontent = document.getElementsByClassName(\"tabcontent\");\n",
       "    for (i = 0; i < tabcontent.length; i++) {\n",
       "        tabcontent[i].style.display = \"none\";\n",
       "    }\n",
       "\n",
       "    // Get all elements with class=\"tablinks\" and remove the class \"active\"\n",
       "    tablinks = document.getElementsByClassName(\"tablinks\");\n",
       "    for (i = 0; i < tablinks.length; i++) {\n",
       "        tablinks[i].className = tablinks[i].className.replace(\" active\", \"\");\n",
       "    }\n",
       "\n",
       "    // Show the current tab, and add an \"active\" class to the button that opened the tab\n",
       "    document.getElementById(name).style.display = \"block\";\n",
       "    evt.currentTarget.className += \" active\";\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<giskard.rag.report.RAGReport at 0x25551303e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_html(\"report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the correctness results organized by question type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversational</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distracting element</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>situational</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     correctness\n",
       "question_type                   \n",
       "complex                      1.0\n",
       "conversational               0.0\n",
       "distracting element          0.0\n",
       "double                       0.0\n",
       "simple                       1.0\n",
       "situational                  1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.correctness_by_question_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display the specific failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_context</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>metadata</th>\n",
       "      <th>agent_answer</th>\n",
       "      <th>correctness</th>\n",
       "      <th>correctness_reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>964fc6fa-491d-4b6a-aa9d-835328b2443e</th>\n",
       "      <td>What does the Machine Learning Systems course ...</td>\n",
       "      <td>The Machine Learning Systems course offers 18 ...</td>\n",
       "      <td>Document 0: Building Machine Learning Systems ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "      <td>The Machine Learning Systems course offers 10 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer includes details that are n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7fb7d403-67a1-429b-bc19-d5d014074a0f</th>\n",
       "      <td>What does the Machine Learning Systems course ...</td>\n",
       "      <td>The Machine Learning Systems course offers 18 ...</td>\n",
       "      <td>Document 0: Building Machine Learning Systems ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "      <td>The Machine Learning Systems course offers pra...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer includes details that are n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2</th>\n",
       "      <td>What is the cost for joining the Machine Learn...</td>\n",
       "      <td>The cost for joining the Machine Learning prog...</td>\n",
       "      <td>Document 9: pay once to join the program and g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'simple', 'seed_document_id'...</td>\n",
       "      <td>The cost for joining the Machine Learning prog...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer is incorrect because it doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e</th>\n",
       "      <td>What resources and benefits can I expect to re...</td>\n",
       "      <td>When you join, you get lifetime access to 18 h...</td>\n",
       "      <td>Document 0: Building Machine Learning Systems ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'complex', 'seed_document_id...</td>\n",
       "      <td>Upon enrolling in the Machine Learning Systems...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer does not match the ground t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8881989e-d95f-462f-931d-8604a75139f7</th>\n",
       "      <td>Could you provide information about the instru...</td>\n",
       "      <td>The instructor of the program is Santiago. He ...</td>\n",
       "      <td>Document 9: pay once to join the program and g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>The instructor of the Machine Learning program...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer is partially correct but it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf85c206-d8e7-465d-a2a1-040f91ac49aa</th>\n",
       "      <td>What is the cost of the program that includes ...</td>\n",
       "      <td>The cost of the program is $450. It includes l...</td>\n",
       "      <td>Document 9: pay once to join the program and g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>The cost of the program is a one-time payment ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not provide the specific cost of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a805b425-f0b8-480a-9bb7-bbceb19263d2</th>\n",
       "      <td>Considering the course 'Building Machine Learn...</td>\n",
       "      <td>The cost of the program is $450. This includes...</td>\n",
       "      <td>Document 5: work.Wednesday: Optional office ho...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>The course 'Building Machine Learning Systems ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not provide the correct cost of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b07946fd-28af-42d6-9117-8959af8b1d9d</th>\n",
       "      <td>What is the cost to join the program that incl...</td>\n",
       "      <td>The cost to join the program is $450. It inclu...</td>\n",
       "      <td>Document 9: pay once to join the program and g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>The cost to join the program that includes des...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent did not provide the specific cost of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3af5418-5b97-4397-8173-d7238e219adf</th>\n",
       "      <td>Considering the program's time commitment, wha...</td>\n",
       "      <td>The second session of the course covers topics...</td>\n",
       "      <td>Document 7: labels and weak supervision.Active...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'distracting element', 'seed...</td>\n",
       "      <td>For those interested in implementing the codin...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer does not match the ground t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99d154a1-d88b-4f11-9ab2-428289571c34</th>\n",
       "      <td>What is included in the machine learning progr...</td>\n",
       "      <td>The program includes 10 hours of step-by-step ...</td>\n",
       "      <td>Document 1: use this time to discuss the first...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'double', 'original_question...</td>\n",
       "      <td>The machine learning program includes live, in...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer is missing some key compone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78b34b08-ca60-446f-a5a5-842f7201fd20</th>\n",
       "      <td>Who is the instructor of the Machine Learning ...</td>\n",
       "      <td>The instructor of the program is Santiago, a m...</td>\n",
       "      <td>Document 9: pay once to join the program and g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'question_type': 'double', 'original_question...</td>\n",
       "      <td>The instructor of the Machine Learning program...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer is partially correct but it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cac32512-57fb-4fe5-a5b8-7144603af758</th>\n",
       "      <td>What topics are covered in this?</td>\n",
       "      <td>Session 2 covers topics such as data cleaning,...</td>\n",
       "      <td>Document 7: labels and weak supervision.Active...</td>\n",
       "      <td>[{'role': 'user', 'content': 'I am interested ...</td>\n",
       "      <td>{'question_type': 'conversational', 'seed_docu...</td>\n",
       "      <td>The topics covered in this context include act...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer is mostly correct but it mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd</th>\n",
       "      <td>What is it?</td>\n",
       "      <td>The upcoming cohorts are: Cohort 12 from April...</td>\n",
       "      <td>Document 4: I've learned from real-life exampl...</td>\n",
       "      <td>[{'role': 'user', 'content': 'I'm interested i...</td>\n",
       "      <td>{'question_type': 'conversational', 'seed_docu...</td>\n",
       "      <td>The context is describing a live, interactive ...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer does not match the ground t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e6cda154-a80e-4c23-8263-a416fe97b92e</th>\n",
       "      <td>What does it offer?</td>\n",
       "      <td>The Machine Learning course offers 18 hours of...</td>\n",
       "      <td>Document 0: Building Machine Learning Systems ...</td>\n",
       "      <td>[{'role': 'user', 'content': 'I'm considering ...</td>\n",
       "      <td>{'question_type': 'conversational', 'seed_docu...</td>\n",
       "      <td>The program offers lifetime access to every pa...</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent's answer includes details that are n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4c572d77-a5eb-42cd-bfd8-e8ec54917f93</th>\n",
       "      <td>Can you provide details about these?</td>\n",
       "      <td>The program costs $450. It includes 18 hours o...</td>\n",
       "      <td>Document 9: pay once to join the program and g...</td>\n",
       "      <td>[{'role': 'user', 'content': 'I am interested ...</td>\n",
       "      <td>{'question_type': 'conversational', 'seed_docu...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent failed to provide the requested deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902beb0e-b9fd-47f6-8f67-dbf94b774577</th>\n",
       "      <td>Could you tell me what they are?</td>\n",
       "      <td>The program costs $450. It includes lifetime a...</td>\n",
       "      <td>Document 5: work.Wednesday: Optional office ho...</td>\n",
       "      <td>[{'role': 'user', 'content': 'I'm interested i...</td>\n",
       "      <td>{'question_type': 'conversational', 'seed_docu...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>False</td>\n",
       "      <td>The agent failed to provide the details of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               question  \\\n",
       "id                                                                                        \n",
       "964fc6fa-491d-4b6a-aa9d-835328b2443e  What does the Machine Learning Systems course ...   \n",
       "7fb7d403-67a1-429b-bc19-d5d014074a0f  What does the Machine Learning Systems course ...   \n",
       "9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2  What is the cost for joining the Machine Learn...   \n",
       "9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e  What resources and benefits can I expect to re...   \n",
       "8881989e-d95f-462f-931d-8604a75139f7  Could you provide information about the instru...   \n",
       "cf85c206-d8e7-465d-a2a1-040f91ac49aa  What is the cost of the program that includes ...   \n",
       "a805b425-f0b8-480a-9bb7-bbceb19263d2  Considering the course 'Building Machine Learn...   \n",
       "b07946fd-28af-42d6-9117-8959af8b1d9d  What is the cost to join the program that incl...   \n",
       "d3af5418-5b97-4397-8173-d7238e219adf  Considering the program's time commitment, wha...   \n",
       "99d154a1-d88b-4f11-9ab2-428289571c34  What is included in the machine learning progr...   \n",
       "78b34b08-ca60-446f-a5a5-842f7201fd20  Who is the instructor of the Machine Learning ...   \n",
       "cac32512-57fb-4fe5-a5b8-7144603af758                   What topics are covered in this?   \n",
       "7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd                                        What is it?   \n",
       "e6cda154-a80e-4c23-8263-a416fe97b92e                                What does it offer?   \n",
       "4c572d77-a5eb-42cd-bfd8-e8ec54917f93               Can you provide details about these?   \n",
       "902beb0e-b9fd-47f6-8f67-dbf94b774577                   Could you tell me what they are?   \n",
       "\n",
       "                                                                       reference_answer  \\\n",
       "id                                                                                        \n",
       "964fc6fa-491d-4b6a-aa9d-835328b2443e  The Machine Learning Systems course offers 18 ...   \n",
       "7fb7d403-67a1-429b-bc19-d5d014074a0f  The Machine Learning Systems course offers 18 ...   \n",
       "9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2  The cost for joining the Machine Learning prog...   \n",
       "9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e  When you join, you get lifetime access to 18 h...   \n",
       "8881989e-d95f-462f-931d-8604a75139f7  The instructor of the program is Santiago. He ...   \n",
       "cf85c206-d8e7-465d-a2a1-040f91ac49aa  The cost of the program is $450. It includes l...   \n",
       "a805b425-f0b8-480a-9bb7-bbceb19263d2  The cost of the program is $450. This includes...   \n",
       "b07946fd-28af-42d6-9117-8959af8b1d9d  The cost to join the program is $450. It inclu...   \n",
       "d3af5418-5b97-4397-8173-d7238e219adf  The second session of the course covers topics...   \n",
       "99d154a1-d88b-4f11-9ab2-428289571c34  The program includes 10 hours of step-by-step ...   \n",
       "78b34b08-ca60-446f-a5a5-842f7201fd20  The instructor of the program is Santiago, a m...   \n",
       "cac32512-57fb-4fe5-a5b8-7144603af758  Session 2 covers topics such as data cleaning,...   \n",
       "7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd  The upcoming cohorts are: Cohort 12 from April...   \n",
       "e6cda154-a80e-4c23-8263-a416fe97b92e  The Machine Learning course offers 18 hours of...   \n",
       "4c572d77-a5eb-42cd-bfd8-e8ec54917f93  The program costs $450. It includes 18 hours o...   \n",
       "902beb0e-b9fd-47f6-8f67-dbf94b774577  The program costs $450. It includes lifetime a...   \n",
       "\n",
       "                                                                      reference_context  \\\n",
       "id                                                                                        \n",
       "964fc6fa-491d-4b6a-aa9d-835328b2443e  Document 0: Building Machine Learning Systems ...   \n",
       "7fb7d403-67a1-429b-bc19-d5d014074a0f  Document 0: Building Machine Learning Systems ...   \n",
       "9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2  Document 9: pay once to join the program and g...   \n",
       "9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e  Document 0: Building Machine Learning Systems ...   \n",
       "8881989e-d95f-462f-931d-8604a75139f7  Document 9: pay once to join the program and g...   \n",
       "cf85c206-d8e7-465d-a2a1-040f91ac49aa  Document 9: pay once to join the program and g...   \n",
       "a805b425-f0b8-480a-9bb7-bbceb19263d2  Document 5: work.Wednesday: Optional office ho...   \n",
       "b07946fd-28af-42d6-9117-8959af8b1d9d  Document 9: pay once to join the program and g...   \n",
       "d3af5418-5b97-4397-8173-d7238e219adf  Document 7: labels and weak supervision.Active...   \n",
       "99d154a1-d88b-4f11-9ab2-428289571c34  Document 1: use this time to discuss the first...   \n",
       "78b34b08-ca60-446f-a5a5-842f7201fd20  Document 9: pay once to join the program and g...   \n",
       "cac32512-57fb-4fe5-a5b8-7144603af758  Document 7: labels and weak supervision.Active...   \n",
       "7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd  Document 4: I've learned from real-life exampl...   \n",
       "e6cda154-a80e-4c23-8263-a416fe97b92e  Document 0: Building Machine Learning Systems ...   \n",
       "4c572d77-a5eb-42cd-bfd8-e8ec54917f93  Document 9: pay once to join the program and g...   \n",
       "902beb0e-b9fd-47f6-8f67-dbf94b774577  Document 5: work.Wednesday: Optional office ho...   \n",
       "\n",
       "                                                                   conversation_history  \\\n",
       "id                                                                                        \n",
       "964fc6fa-491d-4b6a-aa9d-835328b2443e                                                 []   \n",
       "7fb7d403-67a1-429b-bc19-d5d014074a0f                                                 []   \n",
       "9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2                                                 []   \n",
       "9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e                                                 []   \n",
       "8881989e-d95f-462f-931d-8604a75139f7                                                 []   \n",
       "cf85c206-d8e7-465d-a2a1-040f91ac49aa                                                 []   \n",
       "a805b425-f0b8-480a-9bb7-bbceb19263d2                                                 []   \n",
       "b07946fd-28af-42d6-9117-8959af8b1d9d                                                 []   \n",
       "d3af5418-5b97-4397-8173-d7238e219adf                                                 []   \n",
       "99d154a1-d88b-4f11-9ab2-428289571c34                                                 []   \n",
       "78b34b08-ca60-446f-a5a5-842f7201fd20                                                 []   \n",
       "cac32512-57fb-4fe5-a5b8-7144603af758  [{'role': 'user', 'content': 'I am interested ...   \n",
       "7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd  [{'role': 'user', 'content': 'I'm interested i...   \n",
       "e6cda154-a80e-4c23-8263-a416fe97b92e  [{'role': 'user', 'content': 'I'm considering ...   \n",
       "4c572d77-a5eb-42cd-bfd8-e8ec54917f93  [{'role': 'user', 'content': 'I am interested ...   \n",
       "902beb0e-b9fd-47f6-8f67-dbf94b774577  [{'role': 'user', 'content': 'I'm interested i...   \n",
       "\n",
       "                                                                               metadata  \\\n",
       "id                                                                                        \n",
       "964fc6fa-491d-4b6a-aa9d-835328b2443e  {'question_type': 'simple', 'seed_document_id'...   \n",
       "7fb7d403-67a1-429b-bc19-d5d014074a0f  {'question_type': 'simple', 'seed_document_id'...   \n",
       "9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2  {'question_type': 'simple', 'seed_document_id'...   \n",
       "9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e  {'question_type': 'complex', 'seed_document_id...   \n",
       "8881989e-d95f-462f-931d-8604a75139f7  {'question_type': 'distracting element', 'seed...   \n",
       "cf85c206-d8e7-465d-a2a1-040f91ac49aa  {'question_type': 'distracting element', 'seed...   \n",
       "a805b425-f0b8-480a-9bb7-bbceb19263d2  {'question_type': 'distracting element', 'seed...   \n",
       "b07946fd-28af-42d6-9117-8959af8b1d9d  {'question_type': 'distracting element', 'seed...   \n",
       "d3af5418-5b97-4397-8173-d7238e219adf  {'question_type': 'distracting element', 'seed...   \n",
       "99d154a1-d88b-4f11-9ab2-428289571c34  {'question_type': 'double', 'original_question...   \n",
       "78b34b08-ca60-446f-a5a5-842f7201fd20  {'question_type': 'double', 'original_question...   \n",
       "cac32512-57fb-4fe5-a5b8-7144603af758  {'question_type': 'conversational', 'seed_docu...   \n",
       "7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd  {'question_type': 'conversational', 'seed_docu...   \n",
       "e6cda154-a80e-4c23-8263-a416fe97b92e  {'question_type': 'conversational', 'seed_docu...   \n",
       "4c572d77-a5eb-42cd-bfd8-e8ec54917f93  {'question_type': 'conversational', 'seed_docu...   \n",
       "902beb0e-b9fd-47f6-8f67-dbf94b774577  {'question_type': 'conversational', 'seed_docu...   \n",
       "\n",
       "                                                                           agent_answer  \\\n",
       "id                                                                                        \n",
       "964fc6fa-491d-4b6a-aa9d-835328b2443e  The Machine Learning Systems course offers 10 ...   \n",
       "7fb7d403-67a1-429b-bc19-d5d014074a0f  The Machine Learning Systems course offers pra...   \n",
       "9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2  The cost for joining the Machine Learning prog...   \n",
       "9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e  Upon enrolling in the Machine Learning Systems...   \n",
       "8881989e-d95f-462f-931d-8604a75139f7  The instructor of the Machine Learning program...   \n",
       "cf85c206-d8e7-465d-a2a1-040f91ac49aa  The cost of the program is a one-time payment ...   \n",
       "a805b425-f0b8-480a-9bb7-bbceb19263d2  The course 'Building Machine Learning Systems ...   \n",
       "b07946fd-28af-42d6-9117-8959af8b1d9d  The cost to join the program that includes des...   \n",
       "d3af5418-5b97-4397-8173-d7238e219adf  For those interested in implementing the codin...   \n",
       "99d154a1-d88b-4f11-9ab2-428289571c34  The machine learning program includes live, in...   \n",
       "78b34b08-ca60-446f-a5a5-842f7201fd20  The instructor of the Machine Learning program...   \n",
       "cac32512-57fb-4fe5-a5b8-7144603af758  The topics covered in this context include act...   \n",
       "7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd  The context is describing a live, interactive ...   \n",
       "e6cda154-a80e-4c23-8263-a416fe97b92e  The program offers lifetime access to every pa...   \n",
       "4c572d77-a5eb-42cd-bfd8-e8ec54917f93                                      I don't know.   \n",
       "902beb0e-b9fd-47f6-8f67-dbf94b774577                                      I don't know.   \n",
       "\n",
       "                                      correctness  \\\n",
       "id                                                  \n",
       "964fc6fa-491d-4b6a-aa9d-835328b2443e        False   \n",
       "7fb7d403-67a1-429b-bc19-d5d014074a0f        False   \n",
       "9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2        False   \n",
       "9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e        False   \n",
       "8881989e-d95f-462f-931d-8604a75139f7        False   \n",
       "cf85c206-d8e7-465d-a2a1-040f91ac49aa        False   \n",
       "a805b425-f0b8-480a-9bb7-bbceb19263d2        False   \n",
       "b07946fd-28af-42d6-9117-8959af8b1d9d        False   \n",
       "d3af5418-5b97-4397-8173-d7238e219adf        False   \n",
       "99d154a1-d88b-4f11-9ab2-428289571c34        False   \n",
       "78b34b08-ca60-446f-a5a5-842f7201fd20        False   \n",
       "cac32512-57fb-4fe5-a5b8-7144603af758        False   \n",
       "7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd        False   \n",
       "e6cda154-a80e-4c23-8263-a416fe97b92e        False   \n",
       "4c572d77-a5eb-42cd-bfd8-e8ec54917f93        False   \n",
       "902beb0e-b9fd-47f6-8f67-dbf94b774577        False   \n",
       "\n",
       "                                                                     correctness_reason  \n",
       "id                                                                                       \n",
       "964fc6fa-491d-4b6a-aa9d-835328b2443e  The agent's answer includes details that are n...  \n",
       "7fb7d403-67a1-429b-bc19-d5d014074a0f  The agent's answer includes details that are n...  \n",
       "9cf283f9-f19b-4c58-b27b-fca0c5cc7ab2  The agent's answer is incorrect because it doe...  \n",
       "9f9fd3a9-0b3c-48fa-a90b-bd970238cd1e  The agent's answer does not match the ground t...  \n",
       "8881989e-d95f-462f-931d-8604a75139f7  The agent's answer is partially correct but it...  \n",
       "cf85c206-d8e7-465d-a2a1-040f91ac49aa  The agent did not provide the specific cost of...  \n",
       "a805b425-f0b8-480a-9bb7-bbceb19263d2  The agent did not provide the correct cost of ...  \n",
       "b07946fd-28af-42d6-9117-8959af8b1d9d  The agent did not provide the specific cost of...  \n",
       "d3af5418-5b97-4397-8173-d7238e219adf  The agent's answer does not match the ground t...  \n",
       "99d154a1-d88b-4f11-9ab2-428289571c34  The agent's answer is missing some key compone...  \n",
       "78b34b08-ca60-446f-a5a5-842f7201fd20  The agent's answer is partially correct but it...  \n",
       "cac32512-57fb-4fe5-a5b8-7144603af758  The agent's answer is mostly correct but it mi...  \n",
       "7cf1eb03-8c8d-45be-aabd-9ef41cf5f5dd  The agent's answer does not match the ground t...  \n",
       "e6cda154-a80e-4c23-8263-a416fe97b92e  The agent's answer includes details that are n...  \n",
       "4c572d77-a5eb-42cd-bfd8-e8ec54917f93  The agent failed to provide the requested deta...  \n",
       "902beb0e-b9fd-47f6-8f67-dbf94b774577  The agent failed to provide the details of the...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.get_failures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Test Suite\n",
    "\n",
    "We can create a test suite and use it to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test set from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from giskard.rag import QATestset\n",
    "\n",
    "testset = QATestset.load(\"test-set.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Test Suite from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_suite = testset.to_test_suite(\"Machine Learning School Test Suite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function that takes a DataFrame of questions, invokes the chain with each question, and returns the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import giskard\n",
    "\n",
    "\n",
    "def batch_prediction_fn(df: pd.DataFrame):\n",
    "    return chain.batch([{\"question\": q} for q in df[\"question\"].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a Giskard Model object to run our test suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:giskard.models.automodel:Your 'prediction_function' is successfully wrapped by Giskard's 'PredictionFunctionModel' wrapper class.\n"
     ]
    }
   ],
   "source": [
    "giskard_model = giskard.Model(\n",
    "    model=batch_prediction_fn,\n",
    "    model_type=\"text_generation\",\n",
    "    name=\"Machine Learning School Question and Answer Model\",\n",
    "    description=\"This model answers questions about the Machine Learning School website.\",\n",
    "    feature_names=[\"question\"], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run the test suite using the model we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:giskard.datasets.base:Casting dataframe columns from {'question': 'object'} to {'question': 'object'}\n",
      "INFO:giskard.utils.logging_utils:Predicted dataset with shape (10, 5) executed in 0:00:03.577083\n",
      "ERROR:root:An error happened during test execution for test: TestsetCorrectnessTest\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\abdulsamad\\anaconda3\\envs\\evaluation\\Lib\\site-packages\\giskard\\core\\suite.py\", line 573, in run\n",
      "    result = test_partial.giskard_test(**test_params).execute()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\abdulsamad\\anaconda3\\envs\\evaluation\\Lib\\site-packages\\giskard\\registry\\giskard_test.py\", line 192, in execute\n",
      "    return configured_validate_arguments(self.test_fn)(*self.args, **self.kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pydantic\\decorator.py\", line 40, in pydantic.decorator.validate_arguments.validate.wrapper_function\n",
      "  File \"pydantic\\decorator.py\", line 134, in pydantic.decorator.ValidatedFunction.call\n",
      "  File \"pydantic\\decorator.py\", line 206, in pydantic.decorator.ValidatedFunction.execute\n",
      "  File \"c:\\Users\\abdulsamad\\anaconda3\\envs\\evaluation\\Lib\\site-packages\\giskard\\testing\\tests\\llm\\correctness.py\", line 50, in test_llm_correctness\n",
      "    details=eval_result.details,\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'EvaluationResult' object has no attribute 'details'\n",
      "INFO:giskard.core.suite:Executed test suite 'Machine Learning School Test Suite'\n",
      "INFO:giskard.core.suite:result: failed\n",
      "INFO:giskard.core.suite:TestsetCorrectnessTest ({'model': <giskard.models.function.PredictionFunctionModel object at 0x0000025551017850>, 'dataset': <giskard.datasets.base.Dataset object at 0x00000255511FC550>}): {failed, metric=None}\n"
     ]
    }
   ],
   "source": [
    "test_suite_results = test_suite.run(model=giskard_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .alert {\n",
       "        padding: 16px;\n",
       "        border-radius: 4px;\n",
       "        display: flex;\n",
       "        align-items: center;\n",
       "        flex-wrap: wrap;\n",
       "        gap: 4px;\n",
       "        margin-bottom: 16px;\n",
       "    }\n",
       "\n",
       "    .test-result {\n",
       "        border-radius: 4px;\n",
       "        padding: 0 12px;\n",
       "        display: flex;\n",
       "        gap: 4px;\n",
       "        align-items: center;\n",
       "    }\n",
       "\n",
       "    .alert-error, .test-card-failed .test-result {\n",
       "        color: rgb(255, 82, 82);\n",
       "        background: rgb(243, 226, 226);\n",
       "        fill: currentcolor;\n",
       "    }\n",
       "\n",
       "    .test-card-error .test-result {\n",
       "        color: #856404;\n",
       "        background: #fff3cd;\n",
       "        fill: currentcolor;\n",
       "    }\n",
       "\n",
       "    .alert-success, .test-card-passed .test-result {\n",
       "        color: rgb(76, 175, 80);\n",
       "        background: rgb(226, 243, 226);\n",
       "        fill: currentcolor;\n",
       "    }\n",
       "\n",
       "    .alert svg {\n",
       "        height: 24px;\n",
       "        width: 24px;\n",
       "        border-radius: 50%;\n",
       "        background: rgba(0, 0, 0, 10%);\n",
       "    }\n",
       "\n",
       "    .test-result svg {\n",
       "        height: 16px;\n",
       "        width: 16px;\n",
       "    }\n",
       "\n",
       "    .card-container {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "        gap: 16px;\n",
       "    }\n",
       "\n",
       "    .test-card {\n",
       "        border-radius: 4px;\n",
       "        border: 1px solid #e0e0e0;\n",
       "        color: rgb(98, 98, 98);\n",
       "        background: #fff;\n",
       "    }\n",
       "\n",
       "    .param {\n",
       "        display: flex;\n",
       "        flex-direction: column;\n",
       "    }\n",
       "\n",
       "    .test-card .test-name, .test-card .param-value {\n",
       "        color: #000\n",
       "    }\n",
       "\n",
       "    .test-card-row {\n",
       "        padding: 10px;\n",
       "        display: flex;\n",
       "        gap: 20px;\n",
       "        align-items: center;\n",
       "        flex-wrap: wrap;\n",
       "    }\n",
       "\n",
       "    .test-card-row:last-child {\n",
       "        border-top: 1px solid #dee2e6;\n",
       "    }\n",
       "\n",
       "    .spacer {\n",
       "        flex-grow: 1;\n",
       "    }\n",
       "\n",
       "    .test-card-failed .metric {\n",
       "        color: #b71c1c;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<div class='dark'>\n",
       "    <div id='gsk-suite'>\n",
       "        <div class=\"alert alert-error\">\n",
       "  \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\">\n",
       "    <title>close</title>\n",
       "    <path\n",
       "      d=\"M19,6.41L17.59,5L12,10.59L6.41,5L5,6.41L10.59,12L5,17.59L6.41,19L12,13.41L17.59,19L19,17.59L13.41,12L19,6.41Z\"\n",
       "    />\n",
       "  </svg>\n",
       "  <strong>Test suite failed.</strong>\n",
       "  \n",
       "</div>\n",
       "        <div class='card-container'>\n",
       "  \n",
       "  <div\n",
       "    class='test-card test-card-error'>\n",
       "    <div class='test-card-row'>\n",
       "      <span class='test-name'>Test TestsetCorrectnessTest</span>\n",
       "      <div class='spacer'></div>\n",
       "      \n",
       "      <span class='test-result'>\n",
       "      \n",
       "        <svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24'><title>alert-outline</title>\n",
       "          <path d='M12,2L1,21H23M12,6L19.53,19H4.47M11,10V14H13V10M11,16V18H13V16' />\n",
       "        </svg>\n",
       "        Error\n",
       "      \n",
       "    </span>\n",
       "    </div>\n",
       "    <div class='test-card-row'>\n",
       "      \n",
       "      <div class='param'>\n",
       "        <span>model</span>\n",
       "        <span class='param-value'>Machine Learning School Question and Answer Model</span>\n",
       "      </div>\n",
       "      \n",
       "      <div class='param'>\n",
       "        <span>dataset</span>\n",
       "        <span class='param-value'>QA Testset</span>\n",
       "      </div>\n",
       "      \n",
       "    </div>\n",
       "  </div>\n",
       "  \n",
       "</div>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<TestSuiteResult (failed)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_suite_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating with Pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now integrate our test suite with Pytest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%ipytest` not found.\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "import pytest\n",
    "from giskard.rag import QATestset\n",
    "from giskard.testing.tests.llm import test_llm_correctness\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def dataset():\n",
    "    testset = QATestset.load(\"test-set.jsonl\")\n",
    "    return testset.to_dataset()\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def model():\n",
    "    return giskard_model\n",
    "\n",
    "\n",
    "def test_chain(dataset, model):\n",
    "    test_llm_correctness(model=model, dataset=dataset, threshold=0.5).assert_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
